{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"VGG16_fulldate_model_build_improv_v1x.ipynb","provenance":[{"file_id":"1Chg3TDNL0W-4Zn-kNm2-_VSi3POSt2Qt","timestamp":1651409735229},{"file_id":"1v3m157wSmzu5ZtUhX3Xwq-nwEOUeLB2a","timestamp":1651264187924},{"file_id":"1-4FdKU4owdZ_lQweMIwVLT7bUDEGyVeJ","timestamp":1651074058284}],"collapsed_sections":[],"machine_shape":"hm","background_execution":"on","authorship_tag":"ABX9TyO9J3hucttKuMwAv9jflv+A"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["Check GPU"],"metadata":{"id":"XIkB0i9LmTCm"}},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"id":"AVrjJZ2gmXtO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653687174579,"user_tz":-120,"elapsed":9,"user":{"displayName":"Gracie G. Becongco","userId":"00295426205393146083"}},"outputId":"dcc5a1ee-fee1-4e27-8ade-85f45a153f59"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Fri May 27 21:32:54 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   35C    P0    24W / 300W |      0MiB / 16160MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"markdown","source":["Load Google Drive "],"metadata":{"id":"m5w5xQ54meTz"}},{"cell_type":"code","source":["from google.colab import drive #Only if you are using Google Drive\n","drive.mount('/content/gdrive')\n","drive.mount(\"/content/gdrive\", force_remount=True)\n","%cd /content/gdrive/My\\ Drive/"],"metadata":{"id":"zIQm_fwomemb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Location of spectograms for home location, small sample testing"],"metadata":{"id":"01xeFa4Zmla4"}},{"cell_type":"code","source":["cd final/dataset2/"],"metadata":{"id":"CpuDnvAPmlx7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652395308532,"user_tz":-120,"elapsed":228,"user":{"displayName":"Gracie G. Becongco","userId":"00295426205393146083"}},"outputId":"fe8a6ede-4670-4387-b717-b1ec63861eff"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[Errno 2] No such file or directory: 'final/dataset2/'\n","/content/gdrive/My Drive/final/dataset2\n"]}]},{"cell_type":"markdown","source":[""],"metadata":{"id":"3ql2HmuRmmFb"}},{"cell_type":"code","source":["%tensorflow_version  1.x"],"metadata":{"id":"2jGYM6-jmmZH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652395310586,"user_tz":-120,"elapsed":232,"user":{"displayName":"Gracie G. Becongco","userId":"00295426205393146083"}},"outputId":"dfd3305d-4328-47d3-86c1-94ad372fd463"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["TensorFlow 1.x selected.\n"]}]},{"cell_type":"markdown","source":["**Model**"],"metadata":{"id":"JbMpPeDJmz2Q"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from glob import glob\n","\n","training_dir = '/content/gdrive/MyDrive/final/dataset2/train/' \n","validation_dir = '/content/gdrive/MyDrive/final/dataset2/validation/'\n","test_dir = '/content/gdrive/MyDrive/final/dataset2/test'\n","\n","folders = glob(training_dir + '/*')\n","num_classes = len(folders)\n","print ('Total Classes = ' + str(num_classes))\n","print('Total training classes '+str(len(glob(training_dir + '/*'))))\n","print('Total test classes '+str(len(glob(test_dir + '/*'))))\n","print('Toral validation classes '+str(len(glob(validation_dir + '/*'))))"],"metadata":{"id":"Arx8sN3_m5Cf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652395315708,"user_tz":-120,"elapsed":3747,"user":{"displayName":"Gracie G. Becongco","userId":"00295426205393146083"}},"outputId":"846df904-5aec-414b-c72b-b0a8a2dd0129"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Total Classes = 177\n","Total training classes 177\n","Total test classes 177\n","Toral validation classes 177\n"]}]},{"cell_type":"markdown","source":["Check folders"],"metadata":{"id":"rkcCEMsaGPMJ"}},{"cell_type":"code","source":["import pandas as pd\n","import os\n","import shutil\n","\n","\n","dir1 = '/content/gdrive/MyDrive/final/dataset2/validation'\n","dir2 = '/content/gdrive/MyDrive/final/dataset2/train'\n","dir3 = '/content/gdrive/MyDrive/final/dataset2/test'\n","validations = os.listdir(dir1)\n","trains = os.listdir(dir2)\n","tests = os.listdir(dir3)\n","print(trains)\n","print(tests)\n","#if os.path.isdir(targetdir_chk) == False:\n","    # os.mkdir(targetdir_chk)\n","#    print(targetdir_chk + ' directory does not exist so it was created')\n","\n","list_difference = []\n","for item in validations:\n","  if item not in trains:\n","    list_difference.append(item)\n","\n","print('the following are missing directories:')\n","print(list_difference)\n","\n","#create the missing directories in test\n","for item in list_difference:\n","    print(item)\n","    dir2create = '/Users/gracie/ML/AEA_dataset/freesound/spectograms/validation/'+item\n","    if os.path.isdir(item) == False:\n","        #os.mkdir(dir2create)\n","        print(dir2create + ' created')\n","\n","######################\n","list_difference2 = []\n","for item in tests:\n","  if item not in validations:\n","    list_difference2.append(item)\n","\n","print('the following are missing directories:')\n","print(list_difference2)\n","\n","#create the missing directories in test\n","for item in list_difference2:\n","    print(item)\n","    dir2create = '/Users/gracie/ML/AEA_dataset/freesound/spectograms/validation/'+item\n","    if os.path.isdir(item) == False:\n","        #os.mkdir(dir2create)\n","        print(dir2create + ' created')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_1wnQe2cGlaw","executionInfo":{"status":"ok","timestamp":1652395321101,"user_tz":-120,"elapsed":307,"user":{"displayName":"Gracie G. Becongco","userId":"00295426205393146083"}},"outputId":"36ef4b3e-bf77-4f30-e0f6-71c56f55d96c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['Glass', 'Wind', 'Coin_dropping', 'Door', 'Writing', 'Bark', 'Water', 'Speech', 'Guitar', 'Fart', 'Boiling', 'Shatter', 'Female_speech_and_woman_speaking', 'Squeak', 'Wind_chime', 'Vehicle_horn_and_car_horn_and_honking', 'Alarm', 'Male_speech_and_man_speaking', 'Motor_vehicle_road', 'Electric_guitar', 'Truck', 'Tap', 'Gunshot_and_gunfire', 'Cutlery_and_silverware', 'Purr', 'Burping_and_eructation', 'Sneeze', 'Siren', 'Bass_guitar', 'Explosion', 'Keyboard_musical', 'Bird', 'Speech_synthesizer', 'Crying_and_sobbing', 'Drum', 'Engine', 'Meow', 'Tick', 'Knock', 'Ringtone', 'Frying_food', 'Wood', 'Applause', 'Wind_instrument_and_woodwind_instrument', 'Dishes_and_pots_and_pans', 'Human_group_actions', 'Screech', 'Fire', 'Walk_and_footsteps', 'Bell', 'Rattle', 'Train', 'Stream', 'Laughter', 'Mallet_percussion', 'Hi-hat', 'Packing_tape_and_duct_tape', 'Crash_cymbal', 'Bird_vocalization_and_bird_call_and_bird_song', 'Percussion', 'Skateboard', 'Mechanical_fan', 'Piano', 'Crowd', 'Mechanisms', 'Raindrop', 'Ratchet_and_pawl', 'Fireworks', 'Thunder', 'Gull_and_seagull', 'Marimba_and_xylophone', 'Whispering', 'Cheering', 'Chime', 'Harmonica', 'Brass_instrument', 'Cat', 'Crack', 'Crumpling_and_crinkling', 'Chatter', 'Clock', 'Trumpet', 'Screaming', 'Snare_drum', 'Drill', 'Human_voice', 'Zipper_clothing', 'Harp', 'Gong', 'Cowbell', 'Run', 'Singing', 'Shout', 'Bass_drum', 'Chewing_and_mastication', 'Clapping', 'Insect', 'Sliding_door', 'Giggle', 'Female_singing', 'Keys_jangling', 'Accordion', 'Gasp', 'Fill_with_liquid', 'Chuckle_and_chortle', 'Acoustic_guitar', 'Scissors', 'Dog', 'Tabla', 'Whoosh_and_swoosh_and_swish', 'Yell', 'Male_singing', 'Car', 'Trickle_and_dribble', 'Computer_keyboard', 'Cough', 'Subway_and_metro_and_underground', 'Chirp_and_tweet', 'Rattle_instrument', 'Splash_and_splatter', 'Car_passing_by', 'Glockenspiel', 'Drip', 'Bicycle_bell', 'Thump_and_thud', 'Bowed_string_instrument', 'Hammer', 'Plucked_string_instrument', 'Buzz', 'Race_car_and_auto_racing', 'Crushing', 'Church_bell', 'Drawer_open_or_close', 'Finger_snapping', 'Motorcycle', 'Strum', 'Slam', 'Microwave_oven', 'Doorbell', 'Cupboard_open_or_close', 'Livestock_and_farm_animals_and_working_animals', 'Boom', 'Tearing', 'Engine_starting', 'Sawing', 'Fixed-wing_aircraft_and_airplane', 'Liquid', 'Frog', 'Crackle', 'Organ', 'Bus', 'Waves_and_surf', 'Tambourine', 'Printer', 'Camera', 'Accelerating_and_revving_and_vroom', 'Hiss', 'Idling', 'Scratching_performance_technique', 'Chicken_and_rooster', 'Domestic_sounds_and_home_sounds', 'Traffic_noise_and_roadway_noise', 'Child_speech_and_kid_speaking', 'Tick-tock', 'Typing', 'Bathtub_filling_or_washing', 'Cricket', 'Growling', 'Boat_and_Water_vehicle', 'Sink_filling_or_washing', 'Toilet_flush', 'Musical_instrument', 'Chink_and_clink', 'Crow', 'Water_tap_and_faucet', 'Typewriter', 'Sigh', '.DS_Store']\n","['.DS_Store', 'Insect', 'Snare_drum', 'Cat', 'Shout', 'Bark', 'Car_passing_by', 'Siren', 'Wood', 'Drip', 'Chime', 'Gull_and_seagull', 'Wind_chime', 'Drill', 'Hi-hat', 'Gunshot_and_gunfire', 'Chuckle_and_chortle', 'Piano', 'Tabla', 'Car', 'Applause', 'Waves_and_surf', 'Hammer', 'Mechanisms', 'Livestock_and_farm_animals_and_working_animals', 'Cutlery_and_silverware', 'Fixed-wing_aircraft_and_airplane', 'Crackle', 'Bowed_string_instrument', 'Crack', 'Slam', 'Screaming', 'Dishes_and_pots_and_pans', 'Computer_keyboard', 'Raindrop', 'Toilet_flush', 'Chicken_and_rooster', 'Water', 'Dog', 'Speech_synthesizer', 'Traffic_noise_and_roadway_noise', 'Organ', 'Bird_vocalization_and_bird_call_and_bird_song', 'Tick-tock', 'Singing', 'Crash_cymbal', 'Child_speech_and_kid_speaking', 'Packing_tape_and_duct_tape', 'Zipper_clothing', 'Harp', 'Accordion', 'Doorbell', 'Cough', 'Chewing_and_mastication', 'Cricket', 'Growling', 'Camera', 'Musical_instrument', 'Mechanical_fan', 'Male_singing', 'Printer', 'Stream', 'Yell', 'Trumpet', 'Glockenspiel', 'Drum', 'Cupboard_open_or_close', 'Fireworks', 'Brass_instrument', 'Male_speech_and_man_speaking', 'Harmonica', 'Female_singing', 'Purr', 'Crow', 'Scratching_performance_technique', 'Wind', 'Motorcycle', 'Liquid', 'Guitar', 'Bus', 'Walk_and_footsteps', 'Chink_and_clink', 'Chatter', 'Plucked_string_instrument', 'Human_group_actions', 'Tap', 'Tearing', 'Strum', 'Whispering', 'Acoustic_guitar', 'Speech', 'Percussion', 'Squeak', 'Bass_drum', 'Whoosh_and_swoosh_and_swish', 'Typing', 'Crowd', 'Mallet_percussion', 'Glass', 'Subway_and_metro_and_underground', 'Female_speech_and_woman_speaking', 'Boiling', 'Thump_and_thud', 'Tambourine', 'Fart', 'Fire', 'Truck', 'Bird', 'Laughter', 'Keys_jangling', 'Water_tap_and_faucet', 'Engine_starting', 'Sink_filling_or_washing', 'Electric_guitar', 'Clapping', 'Vehicle_horn_and_car_horn_and_honking', 'Bicycle_bell', 'Skateboard', 'Domestic_sounds_and_home_sounds', 'Splash_and_splatter', 'Explosion', 'Rattle', 'Fill_with_liquid', 'Train', 'Crying_and_sobbing', 'Wind_instrument_and_woodwind_instrument', 'Hiss', 'Bell', 'Boom', 'Finger_snapping', 'Typewriter', 'Cowbell', 'Scissors', 'Meow', 'Burping_and_eructation', 'Church_bell', 'Idling', 'Ratchet_and_pawl', 'Ringtone', 'Boat_and_Water_vehicle', 'Cheering', 'Alarm', 'Run', 'Frog', 'Trickle_and_dribble', 'Crumpling_and_crinkling', 'Buzz', 'Frying_food', 'Drawer_open_or_close', 'Human_voice', 'Microwave_oven', 'Rattle_instrument', 'Gasp', 'Bathtub_filling_or_washing', 'Shatter', 'Engine', 'Screech', 'Sliding_door', 'Gong', 'Crushing', 'Motor_vehicle_road', 'Race_car_and_auto_racing', 'Accelerating_and_revving_and_vroom', 'Knock', 'Coin_dropping', 'Marimba_and_xylophone', 'Sigh', 'Keyboard_musical', 'Bass_guitar', 'Clock', 'Sneeze', 'Chirp_and_tweet', 'Door', 'Giggle', 'Sawing', 'Thunder', 'Tick', 'Writing']\n","the following are missing directories:\n","[]\n","the following are missing directories:\n","[]\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from glob import glob\n","\n","training_dir = '/content/gdrive/MyDrive/final/dataset2/train/' \n","validation_dir = '/content/gdrive/MyDrive/final/dataset2/validation/'\n","test_dir = '/content/gdrive/MyDrive/final/dataset2/test'\n","\n","folders = glob(training_dir + '/*')\n","num_classes = len(folders)\n","print ('Total Classes = ' + str(num_classes))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652395325988,"user_tz":-120,"elapsed":207,"user":{"displayName":"Gracie G. Becongco","userId":"00295426205393146083"}},"outputId":"4744ede1-a7ab-4486-e734-18f56bee626b","id":"cUjThwcyGf9X"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Total Classes = 177\n"]}]},{"cell_type":"markdown","source":["Import Libraries"],"metadata":{"id":"rDpcsCKrm7aj"}},{"cell_type":"code","source":["# importing requried libraries\n","from keras import applications\n","from keras.models import Model\n","import keras \n","from keras.applications.vgg16 import VGG16 #Importing the VGG16 Model\n","from keras.layers import Flatten, Dense, Dropout, GlobalAveragePooling2D,BatchNormalization\n","from keras.applications import VGG16, MobileNetV2\n","from keras.optimizers import SGD\n","import tensorflow as tf\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.applications.vgg16 import preprocess_input  "],"metadata":{"id":"Q1UZUp2FW8gX","executionInfo":{"status":"ok","timestamp":1652395333475,"user_tz":-120,"elapsed":3455,"user":{"displayName":"Gracie G. Becongco","userId":"00295426205393146083"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"06c5a7be-94d3-4976-d801-2f2eb9212821"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Using TensorFlow backend.\n"]}]},{"cell_type":"markdown","source":["**StratifiedKFold**"],"metadata":{"id":"Zg7mtAasscb0"}},{"cell_type":"code","source":["def train_model_naive_split():\n","  all_history = {}\n","\n","  inp_train_gen = ImageDataGenerator(\n","    rescale=1. / 255,\n","    rotation_range=260,\n","    width_shift_range=0.4,\n","    height_shift_range=0.4,\n","    shear_range=0.2,\n","    zoom_range=0.4,\n","    horizontal_flip=True,\n","    vertical_flip=True,\n","    fill_mode='nearest',\n","  )\n","\n","  train_data = pd.read_csv('/content/gdrive/MyDrive/final/mytrain.csv')\n","  train_data['label'] = train_data['label'].astype(str)\n","  Y = train_data[['label']]\n","\n","  skf = StratifiedKFold(n_splits = 5, random_state = 7, shuffle = True) \n","\n","  fold = 1\n","  for train_index, val_index in skf.split(np.zeros(len(train_data)),Y):\n","    training_data = train_data.iloc[train_index]\n","    validation_data = train_data.iloc[val_index]\n","\n","    train_iterator = inp_train_gen.flow_from_dataframe(training_data,\n","                                                        x_col='image_id',\n","                                                        y_col='label',\n","                                                        directory='/content/gdrive/MyDrive/final/dataset2/train',\n","                                                        target_size=IMG_SIZE,\n","                                                        batch_size=BATCH_SIZE,\n","                                                        class_mode='categorical',\n","                                                        shuffle=True)\n","\n","    validation_iterator = inp_train_gen.flow_from_dataframe(validation_data,\n","                                                x_col='image_id',\n","                                                y_col='label',\n","                                                directory='/content/gdrive/MyDrive/final/dataset2/validation',\n","                                                target_size=IMG_SIZE,\n","                                                batch_size=BATCH_SIZE,\n","                                                class_mode='categorical',\n","                                                shuffle=True)\n","\n","    model = create_cnn_model()\n","\n","    model_name = f'/content/gdrive/MyDrive/final/best-model-kfold-{fold}.hdf5'\n","    history = model.fit(train_iterator,\n","                        validation_data=validation_iterator,\n","                        epochs=EPOCHS,\n","                        callbacks=create_callbacks(model_name))\n","\n","    all_history[f'history-fold-{fold}'] = history\n","\n","    fold += 1\n","\n","  return all_history\n"],"metadata":{"id":"dEUBYoSKtRx1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Data pre-processing**"],"metadata":{"id":"Xsks4ejQXix4"}},{"cell_type":"code","source":["IMAGE_SIZE = [224,224]\n","\n","training_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n","training_generator = training_datagen.flow_from_directory(directory=training_dir,target_size = IMAGE_SIZE, batch_size = 255, class_mode = 'categorical')\n","validation_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n","validation_generator = validation_datagen.flow_from_directory(directory=validation_dir, target_size = IMAGE_SIZE, batch_size = 255, class_mode = 'categorical')\n","training_generator.class_indices\n"],"metadata":{"id":"jwXoHXEfXPj7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["IMAGE_SIZE = [224,224]\n","\n","training_datagen = ImageDataGenerator(rescale=1./255, zoom_range=0.3, rotation_range=40, \n","                                      width_shift_range=0.3, height_shift_range=0.3, \n","                                      shear_range=0.3, horizontal_flip=True, fill_mode=\"nearest\",\n","                                      preprocessing_function=preprocess_input,\n","                                      samplewise_center=True, samplewise_std_normalization=True)\n","training_generator = training_datagen.flow_from_directory(directory=training_dir,target_size = IMAGE_SIZE, batch_size = 255, class_mode = 'categorical')\n","validation_datagen = ImageDataGenerator(preprocessing_function=preprocess_input, samplewise_center=True, samplewise_std_normalization=True)\n","#validation_generator = validation_datagen.flow_from_directory(directory=validation_dir, target_size = IMAGE_SIZE, batch_size = 255, class_mode = 'categorical')\n","validation_generator = validation_datagen.flow_from_directory(directory=test_dir, target_size = IMAGE_SIZE, batch_size = 255, class_mode = 'categorical')\n","training_generator.class_indices\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652395561549,"user_tz":-120,"elapsed":1609,"user":{"displayName":"Gracie G. Becongco","userId":"00295426205393146083"}},"outputId":"7d80d0f4-3a6c-4e1e-ec2e-11d42f532924","id":"k0Obe4ngcwZ3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 34625 images belonging to 177 classes.\n","Found 4132 images belonging to 177 classes.\n"]},{"output_type":"execute_result","data":{"text/plain":["{'Accelerating_and_revving_and_vroom': 0,\n"," 'Accordion': 1,\n"," 'Acoustic_guitar': 2,\n"," 'Alarm': 3,\n"," 'Applause': 4,\n"," 'Bark': 5,\n"," 'Bass_drum': 6,\n"," 'Bass_guitar': 7,\n"," 'Bathtub_filling_or_washing': 8,\n"," 'Bell': 9,\n"," 'Bicycle_bell': 10,\n"," 'Bird': 11,\n"," 'Bird_vocalization_and_bird_call_and_bird_song': 12,\n"," 'Boat_and_Water_vehicle': 13,\n"," 'Boiling': 14,\n"," 'Boom': 15,\n"," 'Bowed_string_instrument': 16,\n"," 'Brass_instrument': 17,\n"," 'Burping_and_eructation': 18,\n"," 'Bus': 19,\n"," 'Buzz': 20,\n"," 'Camera': 21,\n"," 'Car': 22,\n"," 'Car_passing_by': 23,\n"," 'Cat': 24,\n"," 'Chatter': 25,\n"," 'Cheering': 26,\n"," 'Chewing_and_mastication': 27,\n"," 'Chicken_and_rooster': 28,\n"," 'Child_speech_and_kid_speaking': 29,\n"," 'Chime': 30,\n"," 'Chink_and_clink': 31,\n"," 'Chirp_and_tweet': 32,\n"," 'Chuckle_and_chortle': 33,\n"," 'Church_bell': 34,\n"," 'Clapping': 35,\n"," 'Clock': 36,\n"," 'Coin_dropping': 37,\n"," 'Computer_keyboard': 38,\n"," 'Cough': 39,\n"," 'Cowbell': 40,\n"," 'Crack': 41,\n"," 'Crackle': 42,\n"," 'Crash_cymbal': 43,\n"," 'Cricket': 44,\n"," 'Crow': 45,\n"," 'Crowd': 46,\n"," 'Crumpling_and_crinkling': 47,\n"," 'Crushing': 48,\n"," 'Crying_and_sobbing': 49,\n"," 'Cupboard_open_or_close': 50,\n"," 'Cutlery_and_silverware': 51,\n"," 'Dishes_and_pots_and_pans': 52,\n"," 'Dog': 53,\n"," 'Domestic_sounds_and_home_sounds': 54,\n"," 'Door': 55,\n"," 'Doorbell': 56,\n"," 'Drawer_open_or_close': 57,\n"," 'Drill': 58,\n"," 'Drip': 59,\n"," 'Drum': 60,\n"," 'Electric_guitar': 61,\n"," 'Engine': 62,\n"," 'Engine_starting': 63,\n"," 'Explosion': 64,\n"," 'Fart': 65,\n"," 'Female_singing': 66,\n"," 'Female_speech_and_woman_speaking': 67,\n"," 'Fill_with_liquid': 68,\n"," 'Finger_snapping': 69,\n"," 'Fire': 70,\n"," 'Fireworks': 71,\n"," 'Fixed-wing_aircraft_and_airplane': 72,\n"," 'Frog': 73,\n"," 'Frying_food': 74,\n"," 'Gasp': 75,\n"," 'Giggle': 76,\n"," 'Glass': 77,\n"," 'Glockenspiel': 78,\n"," 'Gong': 79,\n"," 'Growling': 80,\n"," 'Guitar': 81,\n"," 'Gull_and_seagull': 82,\n"," 'Gunshot_and_gunfire': 83,\n"," 'Hammer': 84,\n"," 'Harmonica': 85,\n"," 'Harp': 86,\n"," 'Hi-hat': 87,\n"," 'Hiss': 88,\n"," 'Human_group_actions': 89,\n"," 'Human_voice': 90,\n"," 'Idling': 91,\n"," 'Insect': 92,\n"," 'Keyboard_musical': 93,\n"," 'Keys_jangling': 94,\n"," 'Knock': 95,\n"," 'Laughter': 96,\n"," 'Liquid': 97,\n"," 'Livestock_and_farm_animals_and_working_animals': 98,\n"," 'Male_singing': 99,\n"," 'Male_speech_and_man_speaking': 100,\n"," 'Mallet_percussion': 101,\n"," 'Marimba_and_xylophone': 102,\n"," 'Mechanical_fan': 103,\n"," 'Mechanisms': 104,\n"," 'Meow': 105,\n"," 'Microwave_oven': 106,\n"," 'Motor_vehicle_road': 107,\n"," 'Motorcycle': 108,\n"," 'Musical_instrument': 109,\n"," 'Organ': 110,\n"," 'Packing_tape_and_duct_tape': 111,\n"," 'Percussion': 112,\n"," 'Piano': 113,\n"," 'Plucked_string_instrument': 114,\n"," 'Printer': 115,\n"," 'Purr': 116,\n"," 'Race_car_and_auto_racing': 117,\n"," 'Raindrop': 118,\n"," 'Ratchet_and_pawl': 119,\n"," 'Rattle': 120,\n"," 'Rattle_instrument': 121,\n"," 'Ringtone': 122,\n"," 'Run': 123,\n"," 'Sawing': 124,\n"," 'Scissors': 125,\n"," 'Scratching_performance_technique': 126,\n"," 'Screaming': 127,\n"," 'Screech': 128,\n"," 'Shatter': 129,\n"," 'Shout': 130,\n"," 'Sigh': 131,\n"," 'Singing': 132,\n"," 'Sink_filling_or_washing': 133,\n"," 'Siren': 134,\n"," 'Skateboard': 135,\n"," 'Slam': 136,\n"," 'Sliding_door': 137,\n"," 'Snare_drum': 138,\n"," 'Sneeze': 139,\n"," 'Speech': 140,\n"," 'Speech_synthesizer': 141,\n"," 'Splash_and_splatter': 142,\n"," 'Squeak': 143,\n"," 'Stream': 144,\n"," 'Strum': 145,\n"," 'Subway_and_metro_and_underground': 146,\n"," 'Tabla': 147,\n"," 'Tambourine': 148,\n"," 'Tap': 149,\n"," 'Tearing': 150,\n"," 'Thump_and_thud': 151,\n"," 'Thunder': 152,\n"," 'Tick': 153,\n"," 'Tick-tock': 154,\n"," 'Toilet_flush': 155,\n"," 'Traffic_noise_and_roadway_noise': 156,\n"," 'Train': 157,\n"," 'Trickle_and_dribble': 158,\n"," 'Truck': 159,\n"," 'Trumpet': 160,\n"," 'Typewriter': 161,\n"," 'Typing': 162,\n"," 'Vehicle_horn_and_car_horn_and_honking': 163,\n"," 'Walk_and_footsteps': 164,\n"," 'Water': 165,\n"," 'Water_tap_and_faucet': 166,\n"," 'Waves_and_surf': 167,\n"," 'Whispering': 168,\n"," 'Whoosh_and_swoosh_and_swish': 169,\n"," 'Wind': 170,\n"," 'Wind_chime': 171,\n"," 'Wind_instrument_and_woodwind_instrument': 172,\n"," 'Wood': 173,\n"," 'Writing': 174,\n"," 'Yell': 175,\n"," 'Zipper_clothing': 176}"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["import leave_data as ld\n","import leave_plot as lp\n","import leave_mixup as lm\n","import cosine_lr as clr\n","\n","IMAGE_SIZE = [224,224]\n","BATCH_SIZE = 255\n","training_dir = '/content/gdrive/MyDrive/final/dataset2/train/' \n","validation_dir = '/content/gdrive/MyDrive/final/dataset2/validation/'\n","test_dir = '/content/gdrive/MyDrive/final/dataset2/test'\n","train_iterator1 = ImageDataGenerator.flow_from_directory(directory=training_dir,\n","                                                   target_size=IMG_SIZE,\n","                                                   batch_size=BATCH_SIZE,\n","                                                   class_mode='categorical',\n","                                                   color_mode='rgb',\n","                                                   subset='training',\n","                                                   shuffle=True)\n","\n","train_iterator2 = ImageDataGenerator.flow_from_directory(directory=training_dir,\n","                                                    target_size=IMG_SIZE,\n","                                                    batch_size=BATCH_SIZE,\n","                                                    class_mode='categorical',\n","                                                    color_mode='rgb',\n","                                                    subset='training',\n","                                                    shuffle=True)\n","\n","train_iterator = lm.CutMixImageDataGenerator(generator1=train_iterator1,\n","                                             generator2=train_iterator2,\n","                                             img_size=IMG_SIZE[0],\n","                                             batch_size=BATCH_SIZE,\n","                                             )\n","\n","validation_iterator = ImageDataGenerator.flow_from_directory(directory=validation_dir,\n","                                                        target_size=IMG_SIZE,\n","                                                        batch_size=BATCH_SIZE,\n","                                                        class_mode='categorical',\n","                                                        color_mode='rgb',\n","                                                        subset='validation',\n","                                                        shuffle=True)\n","log_dir = \"/content/gdrive/MyDrive/final/logs/logs\" + datetime.datetime.now().strftime('%Y%m%d-%H%M%S')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":383},"id":"in1doQQrBTwy","executionInfo":{"status":"error","timestamp":1651419878926,"user_tz":-120,"elapsed":783,"user":{"displayName":"Gracie G. Becongco","userId":"00295426205393146083"}},"outputId":"cefad5a2-70aa-400e-bcc6-18c8a718672c"},"execution_count":null,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-7728a2443f71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mleave_data\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mld\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mleave_plot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mleave_mixup\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcosine_lr\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mclr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'leave_data'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"code","source":["import numpy as np\n","import random\n","\n","\n","class MixupImageDataGenerator():\n","    def __init__(self, generator, dataframe, x_col, y_col, directory, batch_size, img_height, img_width, alpha=0.2, subset=None):\n","        \"\"\"Constructor for mixup image data generator.\n","\n","        Arguments:\n","            generator {object} -- An instance of Keras ImageDataGenerator.\n","            directory {str} -- Image directory.\n","            batch_size {int} -- Batch size.\n","            img_height {int} -- Image height in pixels.\n","            img_width {int} -- Image width in pixels.\n","\n","        Keyword Arguments:\n","            alpha {float} -- Mixup beta distribution alpha parameter. (default: {0.2})\n","            subset {str} -- 'training' or 'validation' if validation_split is specified in\n","            `generator` (ImageDataGenerator).(default: {None})\n","        \"\"\"\n","\n","        self.batch_index = 0\n","        self.batch_size = batch_size\n","        self.alpha = alpha\n","\n","        # First iterator yielding tuples of (x, y)\n","        self.generator1 = generator.flow_from_dataframe(dataframe,\n","                                                        x_col=x_col,\n","                                                        y_col=y_col,\n","                                                        directory=directory,\n","                                                        target_size=(\n","                                                            img_height, img_width),\n","                                                        class_mode=\"categorical\",\n","                                                        batch_size=batch_size,\n","                                                        shuffle=True,\n","                                                        subset=subset)\n","\n","        # Second iterator yielding tuples of (x, y)\n","        self.generator2 = generator.flow_from_dataframe(dataframe,\n","                                                        x_col=x_col,\n","                                                        y_col=y_col,\n","                                                        directory=directory,\n","                                                        target_size=(\n","                                                            img_height, img_width),\n","                                                        class_mode=\"categorical\",\n","                                                        batch_size=batch_size,\n","                                                        shuffle=True,\n","                                                        subset=subset)\n","\n","        # Number of images across all classes in image directory.\n","        self.n = self.generator1.samples\n","\n","    def reset_index(self):\n","        \"\"\"Reset the generator indexes array.\n","        \"\"\"\n","\n","        self.generator1._set_index_array()\n","        self.generator2._set_index_array()\n","\n","    def on_epoch_end(self):\n","        self.reset_index()\n","\n","    def reset(self):\n","        self.batch_index = 0\n","\n","    def __len__(self):\n","        # round up\n","        return (self.n + self.batch_size - 1) // self.batch_size\n","\n","    def get_steps_per_epoch(self):\n","        \"\"\"Get number of steps per epoch based on batch size and\n","        number of images.\n","\n","        Returns:\n","            int -- steps per epoch.\n","        \"\"\"\n","\n","        return self.n // self.batch_size\n","\n","    def __next__(self):\n","        \"\"\"Get next batch input/output pair.\n","\n","        Returns:\n","            tuple -- batch of input/output pair, (inputs, outputs).\n","        \"\"\"\n","\n","        if self.batch_index == 0:\n","            self.reset_index()\n","\n","        current_index = (self.batch_index * self.batch_size) % self.n\n","        if self.n > current_index + self.batch_size:\n","            self.batch_index += 1\n","        else:\n","            self.batch_index = 0\n","\n","        # random sample the lambda value from beta distribution.\n","        l = np.random.beta(self.alpha, self.alpha, self.batch_size)\n","\n","        X_l = l.reshape(self.batch_size, 1, 1, 1)\n","        y_l = l.reshape(self.batch_size, 1)\n","\n","        # Get a pair of inputs and outputs from two iterators.\n","        X1, y1 = self.generator1.next()\n","        X2, y2 = self.generator2.next()\n","\n","        # Perform the mixup.\n","        X = X1 * X_l + X2 * (1 - X_l)\n","        y = y1 * y_l + y2 * (1 - y_l)\n","        return X, y\n","\n","    def __iter__(self):\n","        while True:\n","            yield next(self)\n","\n","\n","class CutMixImageDataGenerator():\n","    def __init__(self, generator1, generator2, img_size, batch_size):\n","        self.batch_index = 0\n","        self.samples = generator1.samples\n","        self.class_indices = generator1.class_indices\n","        self.generator1 = generator1\n","        self.generator2 = generator2\n","        self.img_size = img_size\n","        self.batch_size = batch_size\n","\n","    def reset_index(self):  # Ordering Reset (If Shuffle is True, Shuffle Again)\n","        self.generator1._set_index_array()\n","        self.generator2._set_index_array()\n","\n","    def reset(self):\n","        self.batch_index = 0\n","        self.generator1.reset()\n","        self.generator2.reset()\n","        self.reset_index()\n","\n","    def get_steps_per_epoch(self):\n","        quotient, remainder = divmod(self.samples, self.batch_size)\n","        return (quotient + 1) if remainder else quotient\n","    \n","    def __len__(self):\n","        self.get_steps_per_epoch()\n","\n","    def __next__(self):\n","        if self.batch_index == 0: self.reset()\n","\n","        crt_idx = self.batch_index * self.batch_size\n","        if self.samples > crt_idx + self.batch_size:\n","            self.batch_index += 1\n","        else:  # If current index over number of samples\n","            self.batch_index = 0\n","\n","        reshape_size = self.batch_size\n","        last_step_start_idx = (self.get_steps_per_epoch()-1) * self.batch_size\n","        if crt_idx == last_step_start_idx:\n","            reshape_size = self.samples - last_step_start_idx\n","            \n","        X_1, y_1 = self.generator1.next()\n","        X_2, y_2 = self.generator2.next()\n","        \n","        cut_ratio = np.random.beta(a=1, b=1, size=reshape_size)\n","        cut_ratio = np.clip(cut_ratio, 0.2, 0.8)\n","        label_ratio = cut_ratio.reshape(reshape_size, 1)\n","        cut_img = X_2\n","\n","        X = X_1\n","        for i in range(reshape_size):\n","            cut_size = int((self.img_size-1) * cut_ratio[i])\n","            y1 = random.randint(0, (self.img_size-1) - cut_size)\n","            x1 = random.randint(0, (self.img_size-1) - cut_size)\n","            y2 = y1 + cut_size\n","            x2 = x1 + cut_size\n","            cut_arr = cut_img[i][y1:y2, x1:x2]\n","            cutmix_img = X_1[i]\n","            cutmix_img[y1:y2, x1:x2] = cut_arr\n","            X[i] = cutmix_img\n","            \n","        y = y_1 * (1 - (label_ratio ** 2)) + y_2 * (label_ratio ** 2)\n","        return X, y\n","\n","    def __iter__(self):\n","        while True:\n","            yield next(self)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1ZjE7VWVTBdG","executionInfo":{"status":"ok","timestamp":1651419929560,"user_tz":-120,"elapsed":1458,"user":{"displayName":"Gracie G. Becongco","userId":"00295426205393146083"}},"outputId":"9a1650ad-0a88-417b-f8de-5c235b32355c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[31mERROR: Could not find a version that satisfies the requirement leave_mixup (from versions: none)\u001b[0m\n","\u001b[31mERROR: No matching distribution found for leave_mixup\u001b[0m\n"]}]},{"cell_type":"markdown","source":["Load VGG16"],"metadata":{"id":"EGn7Qp1xnOZB"}},{"cell_type":"code","source":["vgg_model = VGG16(input_shape = IMAGE_SIZE + [3], weights = 'imagenet', include_top = False)  \n","\n","for layer in vgg_model.layers:\n","      layer.trainable = False # Non trainable weights\n","\n","# Create Dense Layers\n","# Add the last layers (Flatten and Dense layers) for our problem\n","x = Flatten()(vgg_model.output) \n","x = Dense(num_classes, activation = 'softmax')(x)\n","x = Dropout(0.5)(x) # Dropout layer to reduce overfitting\n","\n","transfer_model = Model(inputs = vgg_model.input, outputs = x)\n","# Compile model, for this we will be using ADAM optimiser to reach to the global minima while training our model\n","# learning_rate= 5e-5\n","transfer_model.compile(loss=\"categorical_crossentropy\", optimizer='adam', metrics=['accuracy'])\n","#history = transfer_model.fit(X_train, y_train, batch_size = 1, epochs=50, validation_data=(X_test,y_test))\n","\n","#transfer_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) \n","transfer_model.summary() #check summary of the model using this command\n"],"metadata":{"id":"Qco4wTK_tzZn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652395629628,"user_tz":-120,"elapsed":849,"user":{"displayName":"Gracie G. Becongco","userId":"00295426205393146083"}},"outputId":"74fcea4d-a20c-43ba-ba97-89c7701fba2a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_2 (InputLayer)         (None, 224, 224, 3)       0         \n","_________________________________________________________________\n","block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n","_________________________________________________________________\n","block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n","_________________________________________________________________\n","block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n","_________________________________________________________________\n","block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n","_________________________________________________________________\n","block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n","_________________________________________________________________\n","block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n","_________________________________________________________________\n","block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n","_________________________________________________________________\n","block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n","_________________________________________________________________\n","block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n","_________________________________________________________________\n","block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n","_________________________________________________________________\n","block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n","_________________________________________________________________\n","block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n","_________________________________________________________________\n","block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n","_________________________________________________________________\n","block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n","_________________________________________________________________\n","block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n","_________________________________________________________________\n","flatten_2 (Flatten)          (None, 25088)             0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 177)               4440753   \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 177)               0         \n","=================================================================\n","Total params: 19,155,441\n","Trainable params: 4,440,753\n","Non-trainable params: 14,714,688\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":[""],"metadata":{"id":"ziJaGIWPnTNh"}},{"cell_type":"code","source":["history = transfer_model.fit_generator(training_generator,\n","                   steps_per_epoch =136, #Number of iterations = number of training images (49,225) / batch size (255)  \n","                   epochs = 10, \n","                   validation_data = validation_generator,\n","                   validation_steps = 2, #same for validation data 300 validation images\n","                   shuffle = True)\n","#                   callbacks=create_callbacks(log_dir)) \n","transfer_model.save('/content/gdrive/MyDrive/final/AED_A_100_vgg16_full_193_Param.h5')"],"metadata":{"id":"ut8hAYkYu3tx","colab":{"base_uri":"https://localhost:8080/","height":570},"executionInfo":{"status":"error","timestamp":1652395929016,"user_tz":-120,"elapsed":238485,"user":{"displayName":"Gracie G. Becongco","userId":"00295426205393146083"}},"outputId":"9d0a8637-2dda-4e81-931a-db79a8a3a7de"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","Epoch 1/10\n"]},{"output_type":"stream","name":"stderr","text":["/tensorflow-1.15.2/python3.7/keras/utils/data_utils.py:616: UserWarning: The input 59 could not be retrieved. It could be because a worker has died.\n","  UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["  3/136 [..............................] - ETA: 2:40:38 - loss: 10.1109 - accuracy: 0.0327"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-84939a0e811d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m                    \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                    \u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m#same for validation data 300 validation images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                    shuffle = True)\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m#                   callbacks=create_callbacks(log_dir))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtransfer_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive/MyDrive/final/AED_A_100_vgg16_full_193_Param.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-1.15.2/python3.7/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-1.15.2/python3.7/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-1.15.2/python3.7/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-1.15.2/python3.7/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    608\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m                     \u001b[0mfuture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m                     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m                     \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","source":[""],"metadata":{"id":"3Uy4h22anX9o"}},{"cell_type":"code","source":["from keras.models import load_model\n","model = load_model('/content/gdrive/MyDrive/final/AED_A_100_vgg16_full_193_Param.h5')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":353},"id":"A7ifXbhEvwj6","executionInfo":{"status":"error","timestamp":1651402598190,"user_tz":-120,"elapsed":5401,"user":{"displayName":"Gracie G. Becongco","userId":"00295426205393146083"}},"outputId":"37ac6e54-12cb-4072-a57b-b187c586d596"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Using TensorFlow backend.\n"]},{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-f23d6f917117>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive/MyDrive/final/AED_A_100_vgg16_full_193_Param.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tensorflow-1.15.2/python3.7/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_filepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mload_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mload_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-1.15.2/python3.7/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mH5Dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_supported_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mH5Dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mh5dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 584\u001b[0;31m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deserialize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh5dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    585\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'write'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mload_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh5file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-1.15.2/python3.7/keras/engine/saving.py\u001b[0m in \u001b[0;36m_deserialize_model\u001b[0;34m(h5dict, custom_objects, compile)\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmodel_config\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No model found in config.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m     \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_from_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0mmodel_weights_group\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'decode'"]}]},{"cell_type":"code","source":["!pip install 'h5py==2.10.0' --force-reinstall"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":661},"id":"14l9iqlH43ea","executionInfo":{"status":"ok","timestamp":1651108388375,"user_tz":-120,"elapsed":14641,"user":{"displayName":"Gracie G. Becongco","userId":"00295426205393146083"}},"outputId":"a8083dda-6955-40c1-ffd1-d27dfea4a8f7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting h5py==2.10.0\n","  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n","\u001b[K     |████████████████████████████████| 2.9 MB 5.4 MB/s \n","\u001b[?25hCollecting six\n","  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n","Collecting numpy>=1.7\n","  Downloading numpy-1.21.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n","\u001b[K     |████████████████████████████████| 15.7 MB 30.2 MB/s \n","\u001b[?25hInstalling collected packages: six, numpy, h5py\n","  Attempting uninstall: six\n","    Found existing installation: six 1.15.0\n","    Uninstalling six-1.15.0:\n","      Successfully uninstalled six-1.15.0\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.21.6\n","    Uninstalling numpy-1.21.6:\n","      Successfully uninstalled numpy-1.21.6\n","  Attempting uninstall: h5py\n","    Found existing installation: h5py 3.1.0\n","    Uninstalling h5py-3.1.0:\n","      Successfully uninstalled h5py-3.1.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","lucid 0.3.10 requires umap-learn, which is not installed.\n","tensorflow 1.15.2 requires gast==0.2.2, but you have gast 0.5.3 which is incompatible.\n","lucid 0.3.10 requires numpy<=1.19, but you have numpy 1.21.6 which is incompatible.\n","kapre 0.3.7 requires tensorflow>=2.0.0, but you have tensorflow 1.15.2 which is incompatible.\n","google-colab 1.0.0 requires six~=1.15.0, but you have six 1.16.0 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n","albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Successfully installed h5py-2.10.0 numpy-1.21.6 six-1.16.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["h5py","numpy","six"]}}},"metadata":{}}]},{"cell_type":"markdown","source":[""],"metadata":{"id":"31ovqz73ndSS"}},{"cell_type":"code","source":[""],"metadata":{"id":"UgI1iKJS5BqL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Model Testing"],"metadata":{"id":"rXKjbMfLneyQ"}},{"cell_type":"code","source":["from keras.preprocessing.image import array_to_img, img_to_array, load_img\n","from keras.applications.vgg16 import preprocess_input\n","import numpy as np\n","import os\n","img_size = 224\n","dir_loc ='/content/gdrive/MyDrive/final/test'\n","clssN = os.listdir(dir_loc)\n","\n","#clssN = ['Heidelberglaan15','Padualaan101','Padualaan97']\n","count = 0\n","countT = 0\n","for bl in clssN:\n","  src = './dataset/test/' + bl \n","  imgs = os.listdir(src)\n","  count = 0\n","  countT = len(imgs) #total number of images per class\n","  for img in imgs: \n","    im = load_img(src + \"/\" + img)\n","    w,h = im.size\n","    im = im.resize((int(w*0.2),int(h*0.2)))\n","    im = im.resize((img_size,img_size))\n","    x = img_to_array(im)  \n","    x = np.expand_dims(x, axis=0)\n","    x = preprocess_input(x)\n","    x/=255.\n","    probs = transfer_model.predict(x, verbose=0)\n","    maxDet = max(probs[0])\n","    maxIdx = list(probs[0]).index(maxDet) #predicted class with maximum probability\n","    if (clssN[maxIdx]==bl): \n","      count = count + 1  #count for true predictions (true positives)\n","    else:\n","      print(f'Wrong prediction of {bl}  {img}. Predicted as {clssN[maxIdx]}') \n","  print(f'test accuracy for {bl} is {str(count/countT)}')"],"metadata":{"id":"WkH6M5Mev4kJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Using the below code, you will see the output of what building class the model has predicted for this specific image."],"metadata":{"id":"v3oraEgunsE3"}},{"cell_type":"markdown","source":["Plotting loss and accuracy"],"metadata":{"id":"P4HbbDUH8gRH"}},{"cell_type":"code","source":[""],"metadata":{"id":"X_o9ddF5ZPhg"},"execution_count":null,"outputs":[]},{"metadata":{"id":"cj9TNNmkj0Dh","outputId":"fe54f738-c426-4d83-a527-4c2709c5fd74","colab":{"base_uri":"https://localhost:8080/","height":517},"executionInfo":{"status":"error","timestamp":1651402203187,"user_tz":-120,"elapsed":861,"user":{"displayName":"Gracie G. Becongco","userId":"00295426205393146083"}}},"cell_type":"code","source":["#import matplotlib as plt\n","import matplotlib.pyplot as plt\n","f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n","t = f.suptitle('Pre-trained CNN (Transfer Learning) Performance', fontsize=12)\n","f.subplots_adjust(top=0.85, wspace=0.3)\n","\n","epoch_list = list(range(1,31))\n","ax1.plot(epoch_list, history.history['acc'], label='Train Accuracy')\n","ax1.plot(epoch_list, history.history['val_acc'], label='Validation Accuracy')\n","ax1.set_xticks(np.arange(0, 31, 5))\n","ax1.set_ylabel('Accuracy Value')\n","ax1.set_xlabel('Epoch')\n","ax1.set_title('Accuracy')\n","l1 = ax1.legend(loc=\"best\")\n","\n","ax2.plot(epoch_list, history.history['loss'], label='Train Loss')\n","ax2.plot(epoch_list, history.history['val_loss'], label='Validation Loss')\n","ax2.set_xticks(np.arange(0, 31, 5))\n","ax2.set_ylabel('Loss Value')\n","ax2.set_xlabel('Epoch')\n","ax2.set_title('Loss')\n","l2 = ax2.legend(loc=\"best\")"],"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-7ab4190add0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mepoch_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m31\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0max1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Train Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0max1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Validation Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0max1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m31\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 864x288 with 2 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]}]}