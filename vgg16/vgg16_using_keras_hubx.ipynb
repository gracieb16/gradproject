{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"vgg16_using_keras_hubx.ipynb","provenance":[],"machine_shape":"hm","background_execution":"on","collapsed_sections":[],"authorship_tag":"ABX9TyOic2rnTvWuQ6vjwafSYZrE"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["VGG16 model - ALL DATA\n","Creation of VGG16 model for sound recognition\n","Dataset includes Freesound, UrbanSound8k and some custom sounds generated from an iPhone"],"metadata":{"id":"iVA6tFq2nIYQ"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R4TJ1k0PnGAd","executionInfo":{"status":"ok","timestamp":1653674075371,"user_tz":-120,"elapsed":22723,"user":{"displayName":"Gracie G. Becongco","userId":"00295426205393146083"}},"outputId":"2eec6c23-3524-4ae2-9e08-fcc1c3bc7baa"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n","Mounted at /content/gdrive\n","/content/gdrive/My Drive\n"]}],"source":["from google.colab import drive #Only if you are using Google Drive\n","drive.mount('/content/gdrive')\n","drive.mount(\"/content/gdrive\", force_remount=True)\n","%cd /content/gdrive/My\\ Drive/"]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import matplotlib.pylab as plabt\n","import numpy as np\n","import os\n","import PIL\n","import time\n","import datetime\n","import PIL.Image as Image\n","\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","from tensorflow import keras\n","from tensorflow.keras import layers, datasets, models, losses\n","from tensorflow.keras.models import Sequential\n","\n","#from tensorboardcolab import TensorBoardColab, TensorBoardColabCallback\n","\n","\n","%load_ext tensorboard"],"metadata":{"id":"ysLDy2hFnRIG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["batch_size = 32\n","img_height = 224\n","img_width = 224\n","#BATCH_SIZE = 255\n","IMG_SIZE = (224, 224)\n","\n","#train_dir = '/content/gdrive/MyDrive/content/img_dir/combined_data/train'\n","#validation_dir = '/content/gdrive/MyDrive/content/img_dir/combined_data/test/'\n","data_dir = '/content/gdrive/MyDrive/content/img_dir/combined_data/all_labeled/'\n"],"metadata":{"id":"sgKGjUDjnRLD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Get VGG16 model without the top layers"],"metadata":{"id":"wqi4j7_SqEgg"}},{"cell_type":"code","source":["feature_extractor_model = tf.keras.applications.VGG16(weights = 'imagenet', include_top = False, input_shape = (img_width,img_height,3))\n","for layer in feature_extractor_model.layers:\n","  layer.trainable = False\n","feature_extractor_model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gQdLseTioYKn","executionInfo":{"status":"ok","timestamp":1653674101630,"user_tz":-120,"elapsed":7446,"user":{"displayName":"Gracie G. Becongco","userId":"00295426205393146083"}},"outputId":"8e9b9422-154c-41dd-e6d3-73b4deede194"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n","58892288/58889256 [==============================] - 2s 0us/step\n","58900480/58889256 [==============================] - 2s 0us/step\n","Model: \"vgg16\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n","                                                                 \n"," block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n","                                                                 \n"," block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n","                                                                 \n"," block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n","                                                                 \n"," block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n","                                                                 \n"," block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n","                                                                 \n"," block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n","                                                                 \n"," block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n","                                                                 \n"," block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n","                                                                 \n"," block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n","                                                                 \n"," block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n","                                                                 \n"," block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n","                                                                 \n"," block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n","                                                                 \n"," block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n","                                                                 \n"," block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n","                                                                 \n"," block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n","                                                                 \n"," block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n","                                                                 \n"," block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n","                                                                 \n"," block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n","                                                                 \n","=================================================================\n","Total params: 14,714,688\n","Trainable params: 0\n","Non-trainable params: 14,714,688\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["Dataset"],"metadata":{"id":"Zy3If4HmqOOw"}},{"cell_type":"code","source":["train_ds = tf.keras.utils.image_dataset_from_directory(\n","  data_dir,\n","  validation_split=0.2,\n","  subset=\"training\",\n","  seed=123,\n","  image_size=(img_height, img_width),\n","  batch_size=batch_size)\n","#train_ds = tf.keras.applications.vgg16.preprocess_input(train_ds)\n","\n","val_ds = tf.keras.utils.image_dataset_from_directory(\n","  data_dir,\n","  validation_split=0.2,\n","  subset=\"validation\",\n","  seed=123,\n","  image_size=(img_height, img_width),\n","  batch_size=batch_size)\n","#val_ds = tf.keras.applications.vgg16.preprocess_input(val_ds)\n","\n","data_augmentation = tf.keras.Sequential([\n","  tf.keras.layers.RandomFlip('horizontal'),\n","  tf.keras.layers.RandomRotation(0.2),\n","])\n","\n","class_names = np.array(train_ds.class_names)\n","print(class_names)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VQ0FeCSknRNg","executionInfo":{"status":"ok","timestamp":1653674992508,"user_tz":-120,"elapsed":4092,"user":{"displayName":"Gracie G. Becongco","userId":"00295426205393146083"}},"outputId":"1cdcc956-8a9d-4037-9290-60d10dffb57e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 49449 files belonging to 217 classes.\n","Using 39560 files for training.\n","Found 49449 files belonging to 217 classes.\n","Using 9889 files for validation.\n","['Accelerating_and_revving_and_vroom' 'Accordion' 'Acoustic_guitar'\n"," 'Aircraft' 'Alarm' 'Animal' 'Applause' 'Bark' 'Bass_drum' 'Bass_guitar'\n"," 'Bathtub_filling_or_washing' 'Bell' 'Bicycle' 'Bicycle_bell' 'Bird'\n"," 'Bird_vocalization_and_bird_call_and_bird_song' 'Boat_and_Water_vehicle'\n"," 'Boiling' 'Boom' 'Bowed_string_instrument' 'Brass_instrument' 'Breathing'\n"," 'Burping_and_eructation' 'Bus' 'Buzz' 'Camera' 'Car' 'Car_passing_by'\n"," 'Cat' 'Chatter' 'Cheering' 'Chewing_and_mastication'\n"," 'Chicken_and_rooster' 'Child_speech_and_kid_speaking' 'Chime'\n"," 'Chink_and_clink' 'Chirp_and_tweet' 'Chuckle_and_chortle' 'Church_bell'\n"," 'Clapping' 'Clock' 'Coin_dropping' 'Computer_keyboard' 'Conversation'\n"," 'Cough' 'Cowbell' 'Crack' 'Crackle' 'Crash_cymbal' 'Cricket' 'Crow'\n"," 'Crowd' 'Crumpling_and_crinkling' 'Crushing' 'Crying_and_sobbing'\n"," 'Cupboard_open_or_close' 'Cutlery_and_silverware' 'Cymbal'\n"," 'Dishes_and_pots_and_pans' 'Dog' 'Domestic_sounds_and_home_sounds' 'Door'\n"," 'Doorbell' 'Drawer_open_or_close' 'Drill' 'Drip' 'Drum' 'Drum_kit'\n"," 'Electric_guitar' 'Engine' 'Engine_starting' 'Explosion' 'Fart'\n"," 'Female_singing' 'Female_speech_and_woman_speaking' 'Fill_with_liquid'\n"," 'Finger_snapping' 'Fire' 'Fireworks' 'Fixed-wing_aircraft_and_airplane'\n"," 'Fowl' 'Frog' 'Frying_food' 'Gasp' 'Giggle' 'Glass' 'Glockenspiel' 'Gong'\n"," 'Growling' 'Guitar' 'Gull_and_seagull' 'Gunshot_and_gunfire' 'Gurgling'\n"," 'Hammer' 'Hands' 'Harmonica' 'Harp' 'Hi-hat' 'Hiss' 'Human_group_actions'\n"," 'Human_voice' 'Idling' 'Insect' 'Keyboard_musical' 'Keys_jangling'\n"," 'Knock' 'Laughter' 'Liquid'\n"," 'Livestock_and_farm_animals_and_working_animals' 'Male_singing'\n"," 'Male_speech_and_man_speaking' 'Mallet_percussion'\n"," 'Marimba_and_xylophone' 'Mechanical_fan' 'Mechanisms' 'Meow'\n"," 'Microwave_oven' 'Motor_vehicle_road' 'Motorcycle' 'Musical_instrument'\n"," 'Ocean' 'Organ' 'Packing_tape_and_duct_tape' 'Percussion' 'Piano'\n"," 'Plucked_string_instrument' 'Power_tool' 'Printer' 'Purr'\n"," 'Race_car_and_auto_racing' 'Rain' 'Raindrop' 'Ratchet_and_pawl' 'Rattle'\n"," 'Rattle_instrument' 'Respiratory_sounds' 'Ringtone' 'Run' 'Sawing'\n"," 'Scissors' 'Scratching_performance_technique' 'Screaming' 'Screech'\n"," 'Shatter' 'Shout' 'Sigh' 'Singing' 'Sink_filling_or_washing' 'Siren'\n"," 'Skateboard' 'Slam' 'Sliding_door' 'Snare_drum' 'Sneeze' 'Speech'\n"," 'Speech_synthesizer' 'Splash_and_splatter' 'Squeak' 'Stream' 'Strum'\n"," 'Subway_and_metro_and_underground' 'Tabla' 'Tambourine' 'Tap' 'Tearing'\n"," 'Telephone' 'Thump_and_thud' 'Thunder' 'Thunderstorm' 'Tick' 'Tick-tock'\n"," 'Toilet_flush' 'Tools' 'Traffic_noise_and_roadway_noise' 'Train'\n"," 'Trickle_and_dribble' 'Truck' 'Trumpet' 'Typewriter' 'Typing' 'Vehicle'\n"," 'Vehicle_horn_and_car_horn_and_honking' 'Walk_and_footsteps' 'Water'\n"," 'Water_tap_and_faucet' 'Waves_and_surf' 'Whispering'\n"," 'Whoosh_and_swoosh_and_swish' 'Wild_animals' 'Wind' 'Wind_chime'\n"," 'Wind_instrument_and_woodwind_instrument' 'Wood' 'Writing' 'Yell'\n"," 'Zipper_clothing' 'air_conditioner' 'car_horn' 'children_playing'\n"," 'clapping' 'coughing' 'dog_bark' 'door_bells' 'door_open_close'\n"," 'drilling' 'engine_idling' 'gun_shot' 'jackhammer' 'kitchen_exhaust'\n"," 'microwave beeping' 'microwave_beeping' 'person_walking' 'siren'\n"," 'street_music' 'television _on' 'television_on' 'water_faucet']\n"]}]},{"cell_type":"code","source":["normalization_layer = tf.keras.layers.Rescaling(1./255)\n","train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y)) # Where x—images, y—labels.\n","val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y)) # Where x—images, y—labels.\n","\n","AUTOTUNE = tf.data.AUTOTUNE\n","train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n","val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n","\n","for image_batch, labels_batch in train_ds:\n","  print(image_batch.shape)\n","  print(labels_batch.shape)\n","  break\n","  "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P9fIMUH2nRP4","executionInfo":{"status":"ok","timestamp":1653674210235,"user_tz":-120,"elapsed":19879,"user":{"displayName":"Gracie G. Becongco","userId":"00295426205393146083"}},"outputId":"58603c8f-e87f-4066-e805-7be9d5bcbe02"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(32, 224, 224, 3)\n","(32,)\n"]}]},{"cell_type":"markdown","source":["Wrap the pre-trained VGG16 model as a Keras layer with hub. Use the trainable=False argument to freeze the variables, so that the training only modifies the new classifier layer:"],"metadata":{"id":"KJR-g4A_vpgI"}},{"cell_type":"code","source":["feature_extractor_layer = hub.KerasLayer(\n","    feature_extractor_model,\n","    input_shape=(224, 224, 3),\n","    trainable=False)\n","\n","feature_batch = feature_extractor_layer(image_batch)\n","print(feature_batch.shape)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ezIvrLG1nRSn","executionInfo":{"status":"ok","timestamp":1653674220684,"user_tz":-120,"elapsed":10472,"user":{"displayName":"Gracie G. Becongco","userId":"00295426205393146083"}},"outputId":"9aedd04e-71ef-4285-895d-d4ae1bd8df01"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(32, 7, 7, 512)\n"]}]},{"cell_type":"markdown","source":["Create a new sequential model using the pre-trained model hub as the first layer an new classification top layer"],"metadata":{"id":"gEU7MO35vygz"}},{"cell_type":"code","source":["num_classes = len(class_names)\n","\n","model = tf.keras.Sequential([\n","  feature_extractor_layer,\n","  tf.keras.layers.Dense(num_classes)\n","])\n","\n","model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ozMXwVMoKZD-","executionInfo":{"status":"ok","timestamp":1653674221480,"user_tz":-120,"elapsed":802,"user":{"displayName":"Gracie G. Becongco","userId":"00295426205393146083"}},"outputId":"6aa206f3-b8fd-4772-cc85-d584ac3220d3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," keras_layer (KerasLayer)    (None, 7, 7, 512)         14714688  \n","                                                                 \n"," dense (Dense)               (None, 7, 7, 217)         111321    \n","                                                                 \n","=================================================================\n","Total params: 14,826,009\n","Trainable params: 111,321\n","Non-trainable params: 14,714,688\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["Attach a classification head"],"metadata":{"id":"ulNN58UWqmgo"}},{"cell_type":"code","source":["predictions = model(image_batch)\n","predictions.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IyfikNhVqup9","executionInfo":{"status":"ok","timestamp":1653674285763,"user_tz":-120,"elapsed":278,"user":{"displayName":"Gracie G. Becongco","userId":"00295426205393146083"}},"outputId":"1773f996-0e72-4d2e-9ce1-e648034fd352"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([32, 7, 7, 217])"]},"metadata":{},"execution_count":11}]},{"cell_type":"markdown","source":["**Train the model**\n","\n","Use Model.compile to configure the training process and add a tf.keras.callbacks.TensorBoard callback to create and store logs:"],"metadata":{"id":"aGloWykfq0jC"}},{"cell_type":"code","source":["# changed default adam optimizer to a very low learning rate\n","#   optimizer=tf.keras.optimizers.Adam(1e-5),\n","model.compile(\n","  optimizer=tf.keras.optimizers.Adam(1e-3),\n","  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","  metrics=['acc'])\n","\n","log = \"/content/gdrive/MyDrive/content/img_dir/logs/vgg16/all_combined/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n","tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log, histogram_freq=1) # Enable histogram computation for every epoch."],"metadata":{"id":"kvWRYkJGqunU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now use the Model.fit method to train the model.\n","\n","To visualize the training progress in TensorBoard later, create and store logs an a TensorBoard callback."],"metadata":{"id":"n3m_jtpwrWj6"}},{"cell_type":"code","source":[" %reload_ext tensorboard"],"metadata":{"id":"AN26YZWzuLQ6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install tensorboardcolab"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"73VdtHpsuVmZ","executionInfo":{"status":"ok","timestamp":1653675228012,"user_tz":-120,"elapsed":5433,"user":{"displayName":"Gracie G. Becongco","userId":"00295426205393146083"}},"outputId":"a1f40066-31e3-4610-f9cf-4a8f8b493782"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tensorboardcolab\n","  Downloading tensorboardcolab-0.0.22.tar.gz (2.5 kB)\n","Building wheels for collected packages: tensorboardcolab\n","  Building wheel for tensorboardcolab (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for tensorboardcolab: filename=tensorboardcolab-0.0.22-py3-none-any.whl size=3859 sha256=16a6bbcf102ae3abab73ac6e78093d45dbbd92677262d27ada3d34453dadb9b4\n","  Stored in directory: /root/.cache/pip/wheels/69/4e/4a/1c6c267395cb10edded1050df12af165d3254cfce324e80941\n","Successfully built tensorboardcolab\n","Installing collected packages: tensorboardcolab\n","Successfully installed tensorboardcolab-0.0.22\n"]}]},{"cell_type":"code","source":["from tensorboardcolab import TensorBoardColab, TensorBoardColabCallback"],"metadata":{"id":"l4THKsT3ub7X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["NUM_EPOCHS = 40\n","\n","history = model.fit(train_ds,\n","                    validation_data=val_ds,\n","                    epochs=NUM_EPOCHS,\n","                    callbacks=tensorboard_callback)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"TQXjlOWoquib","executionInfo":{"status":"error","timestamp":1653675334162,"user_tz":-120,"elapsed":740,"user":{"displayName":"Gracie G. Becongco","userId":"00295426205393146083"}},"outputId":"fe8cf325-c5b7-4e90-96cf-0d6f459e9df8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Can only generate a valid config for `hub.KerasLayer(handle, ...)`that uses a string `handle`.\n","\n","Got `type(handle)`: <class 'keras.engine.functional.Functional'>\n","Epoch 1/40\n"]},{"output_type":"error","ename":"InvalidArgumentError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m<ipython-input-25-2192fd0d973b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                     callbacks=tensorboard_callback)\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'Equal' defined at (most recent call last):\n    File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n      \"__main__\", mod_spec)\n    File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/usr/local/lib/python3.7/dist-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelapp.py\", line 499, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.7/asyncio/events.py\", line 88, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n      handler_func(fileobj, events)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 577, in _handle_events\n      self._handle_recv()\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 606, in _handle_recv\n      self._run_callback(callback, msg)\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 556, in _run_callback\n      callback(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n      return self.dispatch_shell(stream, msg)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n      handler(stream, idents, msg)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n      user_expressions, allow_stdin)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n      interactivity=interactivity, compiler=compiler, result=result)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n      if self.run_code(code, result):\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-14-2192fd0d973b>\", line 6, in <module>\n      callbacks=tensorboard_callback)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 864, in train_step\n      return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 957, in compute_metrics\n      self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/compile_utils.py\", line 459, in update_state\n      metric_obj.update_state(y_t, y_p, sample_weight=mask)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/metrics_utils.py\", line 70, in decorated\n      update_op = update_state_fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/metrics.py\", line 178, in update_state_fn\n      return ag_update_state(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/metrics.py\", line 729, in update_state\n      matches = ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/metrics.py\", line 4086, in sparse_categorical_accuracy\n      return tf.cast(tf.equal(y_true, y_pred), backend.floatx())\nNode: 'Equal'\nrequired broadcastable shapes\n\t [[{{node Equal}}]] [Op:__inference_train_function_1734]"]}]}]}