{"cells":[{"cell_type":"markdown","metadata":{"id":"XIkB0i9LmTCm"},"source":["Check GPU"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1654118574292,"user":{"displayName":"Gracie G. Becongco","userId":"00295426205393146083"},"user_tz":-120},"id":"23TOba33L4qf","outputId":"ee948c30-4882-4c2d-b7d8-e41554bc424e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Wed Jun  1 21:22:53 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   33C    P0    25W / 300W |      0MiB / 16160MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)"]},{"cell_type":"markdown","metadata":{"id":"m5w5xQ54meTz"},"source":["Load Google Drive "]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5126,"status":"ok","timestamp":1654118582329,"user":{"displayName":"Gracie G. Becongco","userId":"00295426205393146083"},"user_tz":-120},"id":"zIQm_fwomemb","outputId":"d36b4c10-c95f-4212-ee9d-af7b68e41777"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Mounted at /content/gdrive\n","/content/gdrive/My Drive\n"]}],"source":["from google.colab import drive #Only if you are using Google Drive\n","drive.mount('/content/gdrive')\n","drive.mount(\"/content/gdrive\", force_remount=True)\n","%cd /content/gdrive/My\\ Drive/"]},{"cell_type":"markdown","metadata":{"id":"01xeFa4Zmla4"},"source":["Location of spectograms for home location, small sample testing"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1953,"status":"ok","timestamp":1653013916048,"user":{"displayName":"Gracie G. Becongco","userId":"00295426205393146083"},"user_tz":-120},"id":"CpuDnvAPmlx7","outputId":"d4b43493-ba77-4615-e0fc-1fdee1ea1711"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/MyDrive/urbansound/spectograms/protosound/dataset\n"]}],"source":["cd /content/gdrive/MyDrive/urbansound/spectograms/protosound/dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":521,"status":"ok","timestamp":1652911719931,"user":{"displayName":"Gracie G. Becongco","userId":"00295426205393146083"},"user_tz":-120},"id":"VH2FDPlnFZ70","outputId":"1739d506-62e0-4d84-b808-c46dbb274a94"},"outputs":[{"name":"stdout","output_type":"stream","text":["total 746\n","drwx------ 2 root root   4096 May  8 14:51 test\n","drwx------ 2 root root   4096 May  8 14:51 train\n","drwx------ 2 root root   4096 May  8 14:51 validation\n","drwx------ 2 root root   4096 May  8 18:17 timestretch_test\n","drwx------ 2 root root   4096 May 17 15:20 all\n","-rw------- 1 root root 243539 May 17 17:58 urbansound8klabels.csv\n","-rw------- 1 root root 209701 May 17 19:14 urbansound8klabels_v2.csv\n","-rw------- 1 root root 285323 May 18 00:33 urbansound8klabels_v3.csv\n","drwx------ 6 root root   4096 May 18 03:53 protosound\n"]}],"source":["! ls -lrt /content/gdrive/MyDrive/urbansound/spectograms/ "]},{"cell_type":"markdown","metadata":{"id":"3ql2HmuRmmFb"},"source":[""]},{"cell_type":"code","execution_count":3,"metadata":{"id":"2jGYM6-jmmZH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654118592757,"user_tz":-120,"elapsed":365,"user":{"displayName":"Gracie G. Becongco","userId":"00295426205393146083"}},"outputId":"0d8ec1d9-131a-48a6-f9c0-05ddf15319a1"},"outputs":[{"output_type":"stream","name":"stdout","text":["TensorFlow 1.x selected.\n"]}],"source":["%tensorflow_version  1.x"]},{"cell_type":"markdown","metadata":{"id":"JbMpPeDJmz2Q"},"source":["**Model**"]},{"cell_type":"markdown","metadata":{"id":"rkcCEMsaGPMJ"},"source":["Check folders"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":240},"executionInfo":{"elapsed":332,"status":"error","timestamp":1652911740844,"user":{"displayName":"Gracie G. Becongco","userId":"00295426205393146083"},"user_tz":-120},"id":"_1wnQe2cGlaw","outputId":"bc162913-c261-4434-ba99-d61635726fd3"},"outputs":[{"ename":"FileNotFoundError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-0dd25b8e69d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mvalidations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mtrains\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mtests\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/gdrive/MyDrive/urbansound/spectograms/protosound/dataset/validation'"]}],"source":["import pandas as pd\n","import os\n","import shutil\n","\n","dir1 = '/content/gdrive/MyDrive/urbansound/spectograms/protosound/dataset/validation'\n","dir2 = '/content/gdrive/MyDrive/urbansound/spectograms/protosound/dataset/train'\n","dir3 = '/content/gdrive/MyDrive/urbansound/spectograms/protosound/dataset/test'\n","\n","\n","validations = os.listdir(dir1)\n","trains = os.listdir(dir2)\n","tests = os.listdir(dir3)\n","print(trains)\n","print(tests)\n","#if os.path.isdir(targetdir_chk) == False:\n","    # os.mkdir(targetdir_chk)\n","#    print(targetdir_chk + ' directory does not exist so it was created')\n","\n","list_difference = []\n","for item in validations:\n","  if item not in trains:\n","    list_difference.append(item)\n","\n","print('the following are missing directories:')\n","print(list_difference)\n","\n","#create the missing directories in test\n","for item in list_difference:\n","    print(item)\n","    dir2create = '/Users/gracie/ML/AEA_dataset/freesound/spectograms/validation/'+item\n","    if os.path.isdir(item) == False:\n","        #os.mkdir(dir2create)\n","        print(dir2create + ' created')\n","\n","######################\n","list_difference2 = []\n","for item in tests:\n","  if item not in validations:\n","    list_difference2.append(item)\n","\n","print('the following are missing directories:')\n","print(list_difference2)\n","\n","#create the missing directories in test\n","for item in list_difference2:\n","    print(item)\n","    dir2create = '/Users/gracie/ML/AEA_dataset/freesound/spectograms/validation/'+item\n","    if os.path.isdir(item) == False:\n","        #os.mkdir(dir2create)\n","        print(dir2create + ' created')"]},{"cell_type":"markdown","source":["Dataset for protosound only"],"metadata":{"id":"oxp5A9omGx9G"}},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":732,"status":"ok","timestamp":1654118598334,"user":{"displayName":"Gracie G. Becongco","userId":"00295426205393146083"},"user_tz":-120},"id":"cUjThwcyGf9X","outputId":"71aa0028-1706-4a06-da76-429717f1f0dd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Total Classes = 206\n","Total Classes = 206\n","Total training classes 206\n","Total test classes 189\n","Toral validation classes 189\n"]}],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from glob import glob\n","\n","#training_dir = '/content/gdrive/MyDrive/urbansound/spectograms/protosound/dataset/train'\n","training_dir = '/content/gdrive/MyDrive/content/img_dir/us8k_freesound/train/'\n","#validation_dir = '/content/gdrive/MyDrive/content/img_dir/us8k_freesound/all_labeled/'\n","validation_dir = '/content/gdrive/MyDrive/content/img_dir/us8k_freesound/test/'\n","test_dir = '/content/gdrive/MyDrive/content/img_dir/us8k_freesound/test/'\n","\n","folders = glob(training_dir + '/*')\n","num_classes = len(folders)\n","print ('Total Classes = ' + str(num_classes))\n","\n","print ('Total Classes = ' + str(num_classes))\n","print('Total training classes '+str(len(glob(training_dir + '/*'))))\n","print('Total test classes '+str(len(glob(test_dir + '/*'))))\n","print('Toral validation classes '+str(len(glob(validation_dir + '/*'))))"]},{"cell_type":"markdown","metadata":{"id":"rDpcsCKrm7aj"},"source":["Import Libraries"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"Q1UZUp2FW8gX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654118607800,"user_tz":-120,"elapsed":1546,"user":{"displayName":"Gracie G. Becongco","userId":"00295426205393146083"}},"outputId":"b5ac970c-0bcb-431d-f9b0-698276405efb"},"outputs":[{"output_type":"stream","name":"stderr","text":["Using TensorFlow backend.\n"]}],"source":["# importing requried libraries\n","from keras import applications\n","from keras.models import Model\n","import keras \n","from keras.applications.vgg16 import VGG16 #Importing the VGG16 Model\n","from keras.layers import Flatten, Dense, Dropout, GlobalAveragePooling2D,BatchNormalization\n","from keras.applications import VGG16, MobileNetV2\n","from keras.optimizers import SGD\n","import tensorflow as tf\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.applications.vgg16 import preprocess_input  "]},{"cell_type":"markdown","metadata":{"id":"Xsks4ejQXix4"},"source":["**Data pre-processing**"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2159,"status":"ok","timestamp":1654118939519,"user":{"displayName":"Gracie G. Becongco","userId":"00295426205393146083"},"user_tz":-120},"id":"jwXoHXEfXPj7","outputId":"9d41a3cc-9719-4950-f50a-e68a96894982"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 43690 images belonging to 206 classes.\n","Found 5911 images belonging to 189 classes.\n"]},{"output_type":"execute_result","data":{"text/plain":["{'Accelerating_and_revving_and_vroom': 0,\n"," 'Accordion': 1,\n"," 'Acoustic_guitar': 2,\n"," 'Aircraft': 3,\n"," 'Alarm': 4,\n"," 'Animal': 5,\n"," 'Applause': 6,\n"," 'Bark': 7,\n"," 'Bass_drum': 8,\n"," 'Bass_guitar': 9,\n"," 'Bathtub_filling_or_washing': 10,\n"," 'Bell': 11,\n"," 'Bicycle': 12,\n"," 'Bicycle_bell': 13,\n"," 'Bird': 14,\n"," 'Bird_vocalization_and_bird_call_and_bird_song': 15,\n"," 'Boat_and_Water_vehicle': 16,\n"," 'Boiling': 17,\n"," 'Boom': 18,\n"," 'Bowed_string_instrument': 19,\n"," 'Brass_instrument': 20,\n"," 'Breathing': 21,\n"," 'Burping_and_eructation': 22,\n"," 'Bus': 23,\n"," 'Buzz': 24,\n"," 'Camera': 25,\n"," 'Car': 26,\n"," 'Car_passing_by': 27,\n"," 'Cat': 28,\n"," 'Chatter': 29,\n"," 'Cheering': 30,\n"," 'Chewing_and_mastication': 31,\n"," 'Chicken_and_rooster': 32,\n"," 'Child_speech_and_kid_speaking': 33,\n"," 'Chime': 34,\n"," 'Chink_and_clink': 35,\n"," 'Chirp_and_tweet': 36,\n"," 'Chuckle_and_chortle': 37,\n"," 'Church_bell': 38,\n"," 'Clapping': 39,\n"," 'Clock': 40,\n"," 'Coin_dropping': 41,\n"," 'Computer_keyboard': 42,\n"," 'Conversation': 43,\n"," 'Cough': 44,\n"," 'Cowbell': 45,\n"," 'Crack': 46,\n"," 'Crackle': 47,\n"," 'Crash_cymbal': 48,\n"," 'Cricket': 49,\n"," 'Crow': 50,\n"," 'Crowd': 51,\n"," 'Crumpling_and_crinkling': 52,\n"," 'Crushing': 53,\n"," 'Crying_and_sobbing': 54,\n"," 'Cupboard_open_or_close': 55,\n"," 'Cutlery_and_silverware': 56,\n"," 'Cymbal': 57,\n"," 'Dishes_and_pots_and_pans': 58,\n"," 'Dog': 59,\n"," 'Domestic_sounds_and_home_sounds': 60,\n"," 'Door': 61,\n"," 'Doorbell': 62,\n"," 'Drawer_open_or_close': 63,\n"," 'Drill': 64,\n"," 'Drip': 65,\n"," 'Drum': 66,\n"," 'Drum_kit': 67,\n"," 'Electric_guitar': 68,\n"," 'Engine': 69,\n"," 'Engine_starting': 70,\n"," 'Explosion': 71,\n"," 'Fart': 72,\n"," 'Female_singing': 73,\n"," 'Female_speech_and_woman_speaking': 74,\n"," 'Fill_with_liquid': 75,\n"," 'Finger_snapping': 76,\n"," 'Fire': 77,\n"," 'Fireworks': 78,\n"," 'Fixed-wing_aircraft_and_airplane': 79,\n"," 'Fowl': 80,\n"," 'Frog': 81,\n"," 'Frying_food': 82,\n"," 'Gasp': 83,\n"," 'Giggle': 84,\n"," 'Glass': 85,\n"," 'Glockenspiel': 86,\n"," 'Gong': 87,\n"," 'Growling': 88,\n"," 'Guitar': 89,\n"," 'Gull_and_seagull': 90,\n"," 'Gunshot_and_gunfire': 91,\n"," 'Gurgling': 92,\n"," 'Hammer': 93,\n"," 'Hands': 94,\n"," 'Harmonica': 95,\n"," 'Harp': 96,\n"," 'Hi-hat': 97,\n"," 'Hiss': 98,\n"," 'Human_group_actions': 99,\n"," 'Human_voice': 100,\n"," 'Idling': 101,\n"," 'Insect': 102,\n"," 'Keyboard_musical': 103,\n"," 'Keys_jangling': 104,\n"," 'Knock': 105,\n"," 'Laughter': 106,\n"," 'Liquid': 107,\n"," 'Livestock_and_farm_animals_and_working_animals': 108,\n"," 'Male_singing': 109,\n"," 'Male_speech_and_man_speaking': 110,\n"," 'Mallet_percussion': 111,\n"," 'Marimba_and_xylophone': 112,\n"," 'Mechanical_fan': 113,\n"," 'Mechanisms': 114,\n"," 'Meow': 115,\n"," 'Microwave_oven': 116,\n"," 'Motor_vehicle_road': 117,\n"," 'Motorcycle': 118,\n"," 'Musical_instrument': 119,\n"," 'Ocean': 120,\n"," 'Organ': 121,\n"," 'Packing_tape_and_duct_tape': 122,\n"," 'Percussion': 123,\n"," 'Piano': 124,\n"," 'Plucked_string_instrument': 125,\n"," 'Power_tool': 126,\n"," 'Printer': 127,\n"," 'Purr': 128,\n"," 'Race_car_and_auto_racing': 129,\n"," 'Rain': 130,\n"," 'Raindrop': 131,\n"," 'Ratchet_and_pawl': 132,\n"," 'Rattle': 133,\n"," 'Rattle_instrument': 134,\n"," 'Respiratory_sounds': 135,\n"," 'Ringtone': 136,\n"," 'Run': 137,\n"," 'Sawing': 138,\n"," 'Scissors': 139,\n"," 'Scratching_performance_technique': 140,\n"," 'Screaming': 141,\n"," 'Screech': 142,\n"," 'Shatter': 143,\n"," 'Shout': 144,\n"," 'Sigh': 145,\n"," 'Singing': 146,\n"," 'Sink_filling_or_washing': 147,\n"," 'Siren': 148,\n"," 'Skateboard': 149,\n"," 'Slam': 150,\n"," 'Sliding_door': 151,\n"," 'Snare_drum': 152,\n"," 'Sneeze': 153,\n"," 'Speech': 154,\n"," 'Speech_synthesizer': 155,\n"," 'Splash_and_splatter': 156,\n"," 'Squeak': 157,\n"," 'Stream': 158,\n"," 'Strum': 159,\n"," 'Subway_and_metro_and_underground': 160,\n"," 'Tabla': 161,\n"," 'Tambourine': 162,\n"," 'Tap': 163,\n"," 'Tearing': 164,\n"," 'Telephone': 165,\n"," 'Thump_and_thud': 166,\n"," 'Thunder': 167,\n"," 'Thunderstorm': 168,\n"," 'Tick': 169,\n"," 'Tick-tock': 170,\n"," 'Toilet_flush': 171,\n"," 'Tools': 172,\n"," 'Traffic_noise_and_roadway_noise': 173,\n"," 'Train': 174,\n"," 'Trickle_and_dribble': 175,\n"," 'Truck': 176,\n"," 'Trumpet': 177,\n"," 'Typewriter': 178,\n"," 'Typing': 179,\n"," 'Vehicle': 180,\n"," 'Vehicle_horn_and_car_horn_and_honking': 181,\n"," 'Walk_and_footsteps': 182,\n"," 'Water': 183,\n"," 'Water_tap_and_faucet': 184,\n"," 'Waves_and_surf': 185,\n"," 'Whispering': 186,\n"," 'Whoosh_and_swoosh_and_swish': 187,\n"," 'Wild_animals': 188,\n"," 'Wind': 189,\n"," 'Wind_chime': 190,\n"," 'Wind_instrument_and_woodwind_instrument': 191,\n"," 'Wood': 192,\n"," 'Writing': 193,\n"," 'Yell': 194,\n"," 'Zipper_clothing': 195,\n"," 'air_conditioner': 196,\n"," 'car_horn': 197,\n"," 'children_playing': 198,\n"," 'dog_bark': 199,\n"," 'drilling': 200,\n"," 'engine_idling': 201,\n"," 'gun_shot': 202,\n"," 'jackhammer': 203,\n"," 'siren': 204,\n"," 'street_music': 205}"]},"metadata":{},"execution_count":11}],"source":["IMAGE_SIZE = [224,224]\n","BATCH_SIZE = 256\n","\n","training_datagen = ImageDataGenerator(preprocessing_function=preprocess_input,samplewise_center=True, samplewise_std_normalization=True)\n","training_generator = training_datagen.flow_from_directory(directory=training_dir,target_size = IMAGE_SIZE, batch_size = BATCH_SIZE, class_mode = 'categorical')\n","validation_datagen = ImageDataGenerator(preprocessing_function=preprocess_input, samplewise_center=True, samplewise_std_normalization=True)\n","validation_generator = validation_datagen.flow_from_directory(directory=test_dir, target_size = IMAGE_SIZE, batch_size = BATCH_SIZE, class_mode = 'categorical')\n","training_generator.class_indices\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8976,"status":"ok","timestamp":1652983215651,"user":{"displayName":"Gracie G. Becongco","userId":"00295426205393146083"},"user_tz":-120},"id":"SmVwjpi9Rhir","outputId":"3e884ad3-58ba-4489-b2c2-300529eea1f9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 6787 images belonging to 10 classes.\n","Found 1747 images belonging to 10 classes.\n"]},{"data":{"text/plain":["{'air_conditioner': 0,\n"," 'car_horn': 1,\n"," 'children_playing': 2,\n"," 'dog_bark': 3,\n"," 'drilling': 4,\n"," 'engine_idling': 5,\n"," 'gun_shot': 6,\n"," 'jackhammer': 7,\n"," 'siren': 8,\n"," 'street_music': 9}"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["# 255 batch size\n","IMAGE_SIZE = [224,224]\n","BATCH_SIZE = 32\n","\n","training_datagen = ImageDataGenerator(rescale=1./255, zoom_range=0.3, rotation_range=40, \n","                                      width_shift_range=0.3, height_shift_range=0.3, \n","                                      shear_range=0.3, horizontal_flip=True, fill_mode=\"nearest\",\n","                                      preprocessing_function=preprocess_input,\n","                                      samplewise_center=True, samplewise_std_normalization=True)\n","training_generator = training_datagen.flow_from_directory(directory=training_dir,target_size = IMAGE_SIZE, batch_size = BATCH_SIZE, class_mode = 'categorical')\n","validation_datagen = ImageDataGenerator(preprocessing_function=preprocess_input, samplewise_center=True, samplewise_std_normalization=True)\n","validation_generator = validation_datagen.flow_from_directory(directory=test_dir, target_size = IMAGE_SIZE, batch_size = BATCH_SIZE, class_mode = 'categorical')\n","training_generator.class_indices\n"]},{"cell_type":"markdown","metadata":{"id":"EGn7Qp1xnOZB"},"source":["Load VGG16, add extra layer and compile"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":768,"status":"ok","timestamp":1654118948804,"user":{"displayName":"Gracie G. Becongco","userId":"00295426205393146083"},"user_tz":-120},"id":"Qco4wTK_tzZn","outputId":"f9a7d1de-904d-400b-83bd-e42b507382c4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_3\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_3 (InputLayer)         (None, 224, 224, 3)       0         \n","_________________________________________________________________\n","block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n","_________________________________________________________________\n","block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n","_________________________________________________________________\n","block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n","_________________________________________________________________\n","block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n","_________________________________________________________________\n","block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n","_________________________________________________________________\n","block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n","_________________________________________________________________\n","block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n","_________________________________________________________________\n","block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n","_________________________________________________________________\n","block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n","_________________________________________________________________\n","block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n","_________________________________________________________________\n","block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n","_________________________________________________________________\n","block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n","_________________________________________________________________\n","block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n","_________________________________________________________________\n","block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n","_________________________________________________________________\n","block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n","_________________________________________________________________\n","flatten_3 (Flatten)          (None, 25088)             0         \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 206)               5168334   \n","_________________________________________________________________\n","dropout_3 (Dropout)          (None, 206)               0         \n","=================================================================\n","Total params: 19,883,022\n","Trainable params: 5,168,334\n","Non-trainable params: 14,714,688\n","_________________________________________________________________\n"]}],"source":["vgg_model = VGG16(input_shape = IMAGE_SIZE + [3], weights = 'imagenet', include_top = False)  \n","\n","for layer in vgg_model.layers:\n","      layer.trainable = False # Non trainable weights\n","\n","# Create Dense Layers\n","# Add the last layers (Flatten and Dense layers) for our problem\n","x = Flatten()(vgg_model.output) \n","x = Dense(num_classes, activation = 'softmax')(x)\n","x = Dropout(0.5)(x) # Dropout layer to reduce overfitting\n","\n","transfer_model = Model(inputs = vgg_model.input, outputs = x)\n","# Compile model, for this we will be using ADAM optimiser to reach to the global minima while training our model\n","# learning_rate= 5e-5\n","transfer_model.compile(loss=\"categorical_crossentropy\", optimizer='adam', metrics=['accuracy'])\n","#history = transfer_model.fit(X_train, y_train, batch_size = 1, epochs=50, validation_data=(X_test,y_test))\n","\n","#transfer_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) \n","transfer_model.summary() #check summary of the model using this command\n"]},{"cell_type":"markdown","metadata":{"id":"ziJaGIWPnTNh"},"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ut8hAYkYu3tx","outputId":"0f12c9aa-699a-4518-82b4-0e017de6994a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n"]},{"output_type":"stream","name":"stderr","text":["/tensorflow-1.15.2/python3.7/keras/utils/data_utils.py:616: UserWarning: The input 96 could not be retrieved. It could be because a worker has died.\n","  UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["\r  1/171 [..............................] - ETA: 6:06:58 - loss: 10.2458 - accuracy: 0.0000e+00"]},{"output_type":"stream","name":"stderr","text":["/tensorflow-1.15.2/python3.7/keras/utils/data_utils.py:616: UserWarning: The input 50 could not be retrieved. It could be because a worker has died.\n","  UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r  2/171 [..............................] - ETA: 6:04:53 - loss: 10.0509 - accuracy: 0.0215    "]},{"output_type":"stream","name":"stderr","text":["/tensorflow-1.15.2/python3.7/keras/utils/data_utils.py:616: UserWarning: The input 104 could not be retrieved. It could be because a worker has died.\n","  UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r  3/171 [..............................] - ETA: 6:03:32 - loss: 10.1360 - accuracy: 0.0312"]},{"output_type":"stream","name":"stderr","text":["/tensorflow-1.15.2/python3.7/keras/utils/data_utils.py:616: UserWarning: The input 70 could not be retrieved. It could be because a worker has died.\n","  UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r  4/171 [..............................] - ETA: 6:01:02 - loss: 10.2978 - accuracy: 0.0342"]},{"output_type":"stream","name":"stderr","text":["/tensorflow-1.15.2/python3.7/keras/utils/data_utils.py:616: UserWarning: The input 15 could not be retrieved. It could be because a worker has died.\n","  UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r  5/171 [..............................] - ETA: 5:58:43 - loss: 10.3485 - accuracy: 0.0414"]},{"output_type":"stream","name":"stderr","text":["/tensorflow-1.15.2/python3.7/keras/utils/data_utils.py:616: UserWarning: The input 117 could not be retrieved. It could be because a worker has died.\n","  UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r  6/171 [>.............................] - ETA: 5:55:04 - loss: 10.4067 - accuracy: 0.0456"]},{"output_type":"stream","name":"stderr","text":["/tensorflow-1.15.2/python3.7/keras/utils/data_utils.py:616: UserWarning: The input 153 could not be retrieved. It could be because a worker has died.\n","  UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r  7/171 [>.............................] - ETA: 5:53:36 - loss: 10.4048 - accuracy: 0.0525"]},{"output_type":"stream","name":"stderr","text":["/tensorflow-1.15.2/python3.7/keras/utils/data_utils.py:616: UserWarning: The input 9 could not be retrieved. It could be because a worker has died.\n","  UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r  8/171 [>.............................] - ETA: 5:52:00 - loss: 10.4449 - accuracy: 0.0547"]},{"output_type":"stream","name":"stderr","text":["/tensorflow-1.15.2/python3.7/keras/utils/data_utils.py:616: UserWarning: The input 36 could not be retrieved. It could be because a worker has died.\n","  UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r  9/171 [>.............................] - ETA: 5:49:59 - loss: 10.5100 - accuracy: 0.0569"]},{"output_type":"stream","name":"stderr","text":["/tensorflow-1.15.2/python3.7/keras/utils/data_utils.py:616: UserWarning: The input 161 could not be retrieved. It could be because a worker has died.\n","  UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 10/171 [>.............................] - ETA: 5:47:35 - loss: 10.4209 - accuracy: 0.0590"]},{"output_type":"stream","name":"stderr","text":["/tensorflow-1.15.2/python3.7/keras/utils/data_utils.py:616: UserWarning: The input 20 could not be retrieved. It could be because a worker has died.\n","  UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 11/171 [>.............................] - ETA: 5:44:34 - loss: 10.4515 - accuracy: 0.0621"]},{"output_type":"stream","name":"stderr","text":["/tensorflow-1.15.2/python3.7/keras/utils/data_utils.py:616: UserWarning: The input 114 could not be retrieved. It could be because a worker has died.\n","  UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 12/171 [=>............................] - ETA: 5:41:32 - loss: 10.4115 - accuracy: 0.0658"]},{"output_type":"stream","name":"stderr","text":["/tensorflow-1.15.2/python3.7/keras/utils/data_utils.py:616: UserWarning: The input 31 could not be retrieved. It could be because a worker has died.\n","  UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 13/171 [=>............................] - ETA: 5:38:57 - loss: 10.4143 - accuracy: 0.0688"]},{"output_type":"stream","name":"stderr","text":["/tensorflow-1.15.2/python3.7/keras/utils/data_utils.py:616: UserWarning: The input 33 could not be retrieved. It could be because a worker has died.\n","  UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 14/171 [=>............................] - ETA: 5:36:39 - loss: 10.3726 - accuracy: 0.0731"]},{"output_type":"stream","name":"stderr","text":["/tensorflow-1.15.2/python3.7/keras/utils/data_utils.py:616: UserWarning: The input 41 could not be retrieved. It could be because a worker has died.\n","  UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 15/171 [=>............................] - ETA: 5:34:11 - loss: 10.3411 - accuracy: 0.0760"]},{"output_type":"stream","name":"stderr","text":["/tensorflow-1.15.2/python3.7/keras/utils/data_utils.py:616: UserWarning: The input 6 could not be retrieved. It could be because a worker has died.\n","  UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 16/171 [=>............................] - ETA: 5:31:53 - loss: 10.2988 - accuracy: 0.0791"]},{"output_type":"stream","name":"stderr","text":["/tensorflow-1.15.2/python3.7/keras/utils/data_utils.py:616: UserWarning: The input 136 could not be retrieved. It could be because a worker has died.\n","  UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 17/171 [=>............................] - ETA: 5:29:35 - loss: 10.2655 - accuracy: 0.0841"]},{"output_type":"stream","name":"stderr","text":["/tensorflow-1.15.2/python3.7/keras/utils/data_utils.py:616: UserWarning: The input 146 could not be retrieved. It could be because a worker has died.\n","  UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 18/171 [==>...........................] - ETA: 5:27:21 - loss: 10.2423 - accuracy: 0.0872"]},{"output_type":"stream","name":"stderr","text":["/tensorflow-1.15.2/python3.7/keras/utils/data_utils.py:616: UserWarning: The input 127 could not be retrieved. It could be because a worker has died.\n","  UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 19/171 [==>...........................] - ETA: 5:24:35 - loss: 10.2089 - accuracy: 0.0919"]},{"output_type":"stream","name":"stderr","text":["/tensorflow-1.15.2/python3.7/keras/utils/data_utils.py:616: UserWarning: The input 2 could not be retrieved. It could be because a worker has died.\n","  UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 20/171 [==>...........................] - ETA: 5:21:59 - loss: 10.2308 - accuracy: 0.0938"]},{"output_type":"stream","name":"stderr","text":["/tensorflow-1.15.2/python3.7/keras/utils/data_utils.py:616: UserWarning: The input 137 could not be retrieved. It could be because a worker has died.\n","  UserWarning)\n"]}],"source":["# 43690 images, 256 batch size \n","history = transfer_model.fit_generator(training_generator,\n","                   steps_per_epoch =171, #Number of iterations = number of training images (49,225) / batch size (255)  \n","                   epochs = 10, \n","                   validation_data = validation_generator,\n","                   validation_steps = 2, #same for validation data 300 validation images\n","                   shuffle = True) \n","transfer_model.save('/content/gdrive/MyDrive/final/vgg16_us8k_urbansound_spp34_10ep.h5')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"NjOJ49d_rAc9","outputId":"00d18518-db32-4cc9-d401-15d603fc0b86"},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","Epoch 1/10\n","267/267 [==============================] - 1083s 4s/step - loss: 0.7286 - accuracy: 0.1191 - val_loss: 1.1921e-07 - val_accuracy: 0.1250\n","Epoch 2/10\n","267/267 [==============================] - 48s 180ms/step - loss: 1.1921e-07 - accuracy: 0.1189 - val_loss: 1.1921e-07 - val_accuracy: 0.1875\n","Epoch 3/10\n","267/267 [==============================] - 48s 180ms/step - loss: 1.1921e-07 - accuracy: 0.1182 - val_loss: 1.1921e-07 - val_accuracy: 0.0938\n","Epoch 4/10\n","267/267 [==============================] - 48s 180ms/step - loss: 1.1921e-07 - accuracy: 0.1171 - val_loss: 1.1921e-07 - val_accuracy: 0.1406\n","Epoch 5/10\n","267/267 [==============================] - 48s 181ms/step - loss: 1.1921e-07 - accuracy: 0.1188 - val_loss: 1.1921e-07 - val_accuracy: 0.0625\n","Epoch 6/10\n","267/267 [==============================] - 48s 180ms/step - loss: 1.1921e-07 - accuracy: 0.1163 - val_loss: 1.1921e-07 - val_accuracy: 0.1719\n","Epoch 7/10\n","267/267 [==============================] - 48s 179ms/step - loss: 1.1921e-07 - accuracy: 0.1210 - val_loss: 1.1921e-07 - val_accuracy: 0.0938\n","Epoch 8/10\n","267/267 [==============================] - 48s 178ms/step - loss: 1.1921e-07 - accuracy: 0.1149 - val_loss: 1.1921e-07 - val_accuracy: 0.1406\n","Epoch 9/10\n","267/267 [==============================] - 47s 175ms/step - loss: 1.1921e-07 - accuracy: 0.1197 - val_loss: 1.1921e-07 - val_accuracy: 0.0781\n","Epoch 10/10\n","267/267 [==============================] - 47s 174ms/step - loss: 1.1921e-07 - accuracy: 0.1138 - val_loss: 1.1921e-07 - val_accuracy: 0.1250\n"]}],"source":["# 8534 images, 32 batch size \n","history = transfer_model.fit_generator(training_generator,\n","                   steps_per_epoch =267, #Number of iterations = number of training images (49,225) / batch size (255)  \n","                   epochs = 10, \n","                   validation_data = validation_generator,\n","                   validation_steps = 2, #same for validation data 300 validation images\n","                   shuffle = True) \n","transfer_model.save('/content/gdrive/MyDrive/final/us8k_TeslaP100_vgg16_267stepsPE_10epochs_Param.h5')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4671983,"status":"ok","timestamp":1653018651638,"user":{"displayName":"Gracie G. Becongco","userId":"00295426205393146083"},"user_tz":-120},"id":"cfxxE2udg2J9","outputId":"9969b4d6-2859-4087-e41e-e35dfd54cbea"},"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","Epoch 1/100\n","267/267 [==============================] - 961s 4s/step - loss: 0.3778 - accuracy: 0.1208 - val_loss: 1.1921e-07 - val_accuracy: 0.0469\n","Epoch 2/100\n","267/267 [==============================] - 37s 139ms/step - loss: 1.1921e-07 - accuracy: 0.1202 - val_loss: 1.1921e-07 - val_accuracy: 0.1250\n","Epoch 3/100\n","267/267 [==============================] - 38s 141ms/step - loss: 1.1921e-07 - accuracy: 0.1159 - val_loss: 1.1921e-07 - val_accuracy: 0.1094\n","Epoch 4/100\n","267/267 [==============================] - 37s 139ms/step - loss: 1.1921e-07 - accuracy: 0.1165 - val_loss: 1.1921e-07 - val_accuracy: 0.1094\n","Epoch 5/100\n","267/267 [==============================] - 37s 139ms/step - loss: 1.1921e-07 - accuracy: 0.1187 - val_loss: 1.1921e-07 - val_accuracy: 0.1406\n","Epoch 6/100\n","267/267 [==============================] - 37s 139ms/step - loss: 1.1921e-07 - accuracy: 0.1162 - val_loss: 1.1921e-07 - val_accuracy: 0.0156\n","Epoch 7/100\n","267/267 [==============================] - 37s 137ms/step - loss: 1.1921e-07 - accuracy: 0.1195 - val_loss: 1.1921e-07 - val_accuracy: 0.0625\n","Epoch 8/100\n","267/267 [==============================] - 37s 139ms/step - loss: 1.1921e-07 - accuracy: 0.1158 - val_loss: 1.1921e-07 - val_accuracy: 0.2031\n","Epoch 9/100\n","267/267 [==============================] - 37s 140ms/step - loss: 1.1921e-07 - accuracy: 0.1200 - val_loss: 1.1921e-07 - val_accuracy: 0.1250\n","Epoch 10/100\n","267/267 [==============================] - 37s 139ms/step - loss: 1.1921e-07 - accuracy: 0.1138 - val_loss: 1.1921e-07 - val_accuracy: 0.1094\n","Epoch 11/100\n","267/267 [==============================] - 37s 140ms/step - loss: 1.1921e-07 - accuracy: 0.1202 - val_loss: 1.1921e-07 - val_accuracy: 0.1250\n","Epoch 12/100\n","267/267 [==============================] - 37s 138ms/step - loss: 1.1921e-07 - accuracy: 0.1154 - val_loss: 1.1921e-07 - val_accuracy: 0.0938\n","Epoch 13/100\n","267/267 [==============================] - 37s 138ms/step - loss: 1.1921e-07 - accuracy: 0.1190 - val_loss: 1.1921e-07 - val_accuracy: 0.0938\n","Epoch 14/100\n","267/267 [==============================] - 37s 138ms/step - loss: 1.1921e-07 - accuracy: 0.1170 - val_loss: 1.1921e-07 - val_accuracy: 0.0938\n","Epoch 15/100\n","267/267 [==============================] - 37s 138ms/step - loss: 1.1921e-07 - accuracy: 0.1170 - val_loss: 1.1921e-07 - val_accuracy: 0.1094\n","Epoch 16/100\n","267/267 [==============================] - 37s 139ms/step - loss: 1.1921e-07 - accuracy: 0.1185 - val_loss: 1.1921e-07 - val_accuracy: 0.1406\n","Epoch 17/100\n","267/267 [==============================] - 37s 139ms/step - loss: 1.1921e-07 - accuracy: 0.1152 - val_loss: 1.1921e-07 - val_accuracy: 0.1250\n","Epoch 18/100\n","267/267 [==============================] - 37s 137ms/step - loss: 1.1921e-07 - accuracy: 0.1233 - val_loss: 1.1921e-07 - val_accuracy: 0.1406\n","Epoch 19/100\n","267/267 [==============================] - 37s 139ms/step - loss: 1.1921e-07 - accuracy: 0.1153 - val_loss: 1.1921e-07 - val_accuracy: 0.1562\n","Epoch 20/100\n","267/267 [==============================] - 37s 138ms/step - loss: 1.1921e-07 - accuracy: 0.1169 - val_loss: 1.1921e-07 - val_accuracy: 0.1094\n","Epoch 21/100\n","267/267 [==============================] - 37s 139ms/step - loss: 1.1921e-07 - accuracy: 0.1143 - val_loss: 1.1921e-07 - val_accuracy: 0.1719\n","Epoch 22/100\n","267/267 [==============================] - 38s 142ms/step - loss: 1.1921e-07 - accuracy: 0.1207 - val_loss: 1.1921e-07 - val_accuracy: 0.1250\n","Epoch 23/100\n","267/267 [==============================] - 37s 138ms/step - loss: 1.1921e-07 - accuracy: 0.1178 - val_loss: 1.1921e-07 - val_accuracy: 0.1250\n","Epoch 24/100\n","267/267 [==============================] - 37s 139ms/step - loss: 1.1921e-07 - accuracy: 0.1165 - val_loss: 1.1921e-07 - val_accuracy: 0.1250\n","Epoch 25/100\n","267/267 [==============================] - 37s 140ms/step - loss: 1.1921e-07 - accuracy: 0.1205 - val_loss: 1.1921e-07 - val_accuracy: 0.0781\n","Epoch 26/100\n","267/267 [==============================] - 37s 138ms/step - loss: 1.1921e-07 - accuracy: 0.1146 - val_loss: 1.1921e-07 - val_accuracy: 0.1094\n","Epoch 27/100\n","267/267 [==============================] - 37s 138ms/step - loss: 1.1921e-07 - accuracy: 0.1176 - val_loss: 1.1921e-07 - val_accuracy: 0.1250\n","Epoch 28/100\n","267/267 [==============================] - 38s 143ms/step - loss: 1.1921e-07 - accuracy: 0.1192 - val_loss: 1.1921e-07 - val_accuracy: 0.0392\n","Epoch 29/100\n","267/267 [==============================] - 37s 137ms/step - loss: 1.1921e-07 - accuracy: 0.1163 - val_loss: 1.1921e-07 - val_accuracy: 0.1875\n","Epoch 30/100\n","267/267 [==============================] - 37s 137ms/step - loss: 1.1921e-07 - accuracy: 0.1144 - val_loss: 1.1921e-07 - val_accuracy: 0.1562\n","Epoch 31/100\n","267/267 [==============================] - 37s 139ms/step - loss: 1.1921e-07 - accuracy: 0.1224 - val_loss: 1.1921e-07 - val_accuracy: 0.2188\n","Epoch 32/100\n","267/267 [==============================] - 37s 138ms/step - loss: 1.1921e-07 - accuracy: 0.1164 - val_loss: 1.1921e-07 - val_accuracy: 0.1562\n","Epoch 33/100\n","267/267 [==============================] - 37s 137ms/step - loss: 1.1921e-07 - accuracy: 0.1181 - val_loss: 1.1921e-07 - val_accuracy: 0.1406\n","Epoch 34/100\n","267/267 [==============================] - 37s 140ms/step - loss: 1.1921e-07 - accuracy: 0.1169 - val_loss: 1.1921e-07 - val_accuracy: 0.0938\n","Epoch 35/100\n","267/267 [==============================] - 37s 138ms/step - loss: 1.1921e-07 - accuracy: 0.1184 - val_loss: 1.1921e-07 - val_accuracy: 0.0781\n","Epoch 36/100\n","267/267 [==============================] - 38s 141ms/step - loss: 1.1921e-07 - accuracy: 0.1163 - val_loss: 1.1921e-07 - val_accuracy: 0.1250\n","Epoch 37/100\n","267/267 [==============================] - 37s 138ms/step - loss: 1.1921e-07 - accuracy: 0.1165 - val_loss: 1.1921e-07 - val_accuracy: 0.0625\n","Epoch 38/100\n","267/267 [==============================] - 37s 139ms/step - loss: 1.1921e-07 - accuracy: 0.1195 - val_loss: 1.1921e-07 - val_accuracy: 0.1250\n","Epoch 39/100\n","267/267 [==============================] - 37s 138ms/step - loss: 1.1921e-07 - accuracy: 0.1157 - val_loss: 1.1921e-07 - val_accuracy: 0.1250\n","Epoch 40/100\n","267/267 [==============================] - 37s 137ms/step - loss: 1.1921e-07 - accuracy: 0.1190 - val_loss: 1.1921e-07 - val_accuracy: 0.1406\n","Epoch 41/100\n","267/267 [==============================] - 37s 137ms/step - loss: 1.1921e-07 - accuracy: 0.1152 - val_loss: 1.1921e-07 - val_accuracy: 0.0781\n","Epoch 42/100\n","267/267 [==============================] - 37s 139ms/step - loss: 1.1921e-07 - accuracy: 0.1192 - val_loss: 1.1921e-07 - val_accuracy: 0.0781\n","Epoch 43/100\n","267/267 [==============================] - 37s 137ms/step - loss: 1.1921e-07 - accuracy: 0.1187 - val_loss: 1.1921e-07 - val_accuracy: 0.1719\n","Epoch 44/100\n","267/267 [==============================] - 37s 139ms/step - loss: 1.1921e-07 - accuracy: 0.1173 - val_loss: 1.1921e-07 - val_accuracy: 0.2031\n","Epoch 45/100\n","267/267 [==============================] - 37s 138ms/step - loss: 1.1921e-07 - accuracy: 0.1178 - val_loss: 1.1921e-07 - val_accuracy: 0.0469\n","Epoch 46/100\n","267/267 [==============================] - 37s 138ms/step - loss: 1.1921e-07 - accuracy: 0.1178 - val_loss: 1.1921e-07 - val_accuracy: 0.1875\n","Epoch 47/100\n","267/267 [==============================] - 38s 143ms/step - loss: 1.1921e-07 - accuracy: 0.1175 - val_loss: 1.1921e-07 - val_accuracy: 0.0312\n","Epoch 48/100\n","267/267 [==============================] - 37s 140ms/step - loss: 1.1921e-07 - accuracy: 0.1165 - val_loss: 1.1921e-07 - val_accuracy: 0.1250\n","Epoch 49/100\n","267/267 [==============================] - 38s 144ms/step - loss: 1.1921e-07 - accuracy: 0.1173 - val_loss: 1.1921e-07 - val_accuracy: 0.0938\n","Epoch 50/100\n","267/267 [==============================] - 38s 141ms/step - loss: 1.1921e-07 - accuracy: 0.1204 - val_loss: 1.1921e-07 - val_accuracy: 0.0781\n","Epoch 51/100\n","267/267 [==============================] - 37s 139ms/step - loss: 1.1921e-07 - accuracy: 0.1145 - val_loss: 1.1921e-07 - val_accuracy: 0.1250\n","Epoch 52/100\n","267/267 [==============================] - 37s 137ms/step - loss: 1.1921e-07 - accuracy: 0.1183 - val_loss: 1.1921e-07 - val_accuracy: 0.0469\n","Epoch 53/100\n","267/267 [==============================] - 37s 137ms/step - loss: 1.1921e-07 - accuracy: 0.1176 - val_loss: 1.1921e-07 - val_accuracy: 0.1094\n","Epoch 54/100\n","267/267 [==============================] - 36s 136ms/step - loss: 1.1921e-07 - accuracy: 0.1168 - val_loss: 1.1921e-07 - val_accuracy: 0.1094\n","Epoch 55/100\n","267/267 [==============================] - 37s 138ms/step - loss: 1.1921e-07 - accuracy: 0.1183 - val_loss: 1.1921e-07 - val_accuracy: 0.0392\n","Epoch 56/100\n","267/267 [==============================] - 37s 139ms/step - loss: 1.1921e-07 - accuracy: 0.1192 - val_loss: 1.1921e-07 - val_accuracy: 0.0469\n","Epoch 57/100\n","267/267 [==============================] - 37s 138ms/step - loss: 1.1921e-07 - accuracy: 0.1180 - val_loss: 1.1921e-07 - val_accuracy: 0.1250\n","Epoch 58/100\n","267/267 [==============================] - 37s 138ms/step - loss: 1.1921e-07 - accuracy: 0.1147 - val_loss: 1.1921e-07 - val_accuracy: 0.1094\n","Epoch 59/100\n","267/267 [==============================] - 37s 139ms/step - loss: 1.1921e-07 - accuracy: 0.1182 - val_loss: 1.1921e-07 - val_accuracy: 0.1250\n","Epoch 60/100\n","267/267 [==============================] - 37s 138ms/step - loss: 1.1921e-07 - accuracy: 0.1185 - val_loss: 1.1921e-07 - val_accuracy: 0.0938\n","Epoch 61/100\n","267/267 [==============================] - 37s 138ms/step - loss: 1.1921e-07 - accuracy: 0.1150 - val_loss: 1.1921e-07 - val_accuracy: 0.1719\n","Epoch 62/100\n","267/267 [==============================] - 37s 139ms/step - loss: 1.1921e-07 - accuracy: 0.1167 - val_loss: 1.1921e-07 - val_accuracy: 0.1719\n","Epoch 63/100\n","267/267 [==============================] - 37s 137ms/step - loss: 1.1921e-07 - accuracy: 0.1216 - val_loss: 1.1921e-07 - val_accuracy: 0.0938\n","Epoch 64/100\n","267/267 [==============================] - 37s 138ms/step - loss: 1.1921e-07 - accuracy: 0.1167 - val_loss: 1.1921e-07 - val_accuracy: 0.0781\n","Epoch 65/100\n","267/267 [==============================] - 36s 137ms/step - loss: 1.1921e-07 - accuracy: 0.1181 - val_loss: 1.1921e-07 - val_accuracy: 0.1250\n","Epoch 66/100\n","267/267 [==============================] - 36s 136ms/step - loss: 1.1921e-07 - accuracy: 0.1150 - val_loss: 1.1921e-07 - val_accuracy: 0.1094\n","Epoch 67/100\n","267/267 [==============================] - 37s 138ms/step - loss: 1.1921e-07 - accuracy: 0.1198 - val_loss: 1.1921e-07 - val_accuracy: 0.1562\n","Epoch 68/100\n","267/267 [==============================] - 36s 136ms/step - loss: 1.1921e-07 - accuracy: 0.1164 - val_loss: 1.1921e-07 - val_accuracy: 0.1250\n","Epoch 69/100\n","267/267 [==============================] - 37s 137ms/step - loss: 1.1921e-07 - accuracy: 0.1157 - val_loss: 1.1921e-07 - val_accuracy: 0.0156\n","Epoch 70/100\n","267/267 [==============================] - 36s 137ms/step - loss: 1.1921e-07 - accuracy: 0.1200 - val_loss: 1.1921e-07 - val_accuracy: 0.0781\n","Epoch 71/100\n","267/267 [==============================] - 38s 141ms/step - loss: 1.1921e-07 - accuracy: 0.1180 - val_loss: 1.1921e-07 - val_accuracy: 0.1094\n","Epoch 72/100\n","267/267 [==============================] - 41s 152ms/step - loss: 1.1921e-07 - accuracy: 0.1170 - val_loss: 1.1921e-07 - val_accuracy: 0.0625\n","Epoch 73/100\n","267/267 [==============================] - 41s 153ms/step - loss: 1.1921e-07 - accuracy: 0.1177 - val_loss: 1.1921e-07 - val_accuracy: 0.1250\n","Epoch 74/100\n","267/267 [==============================] - 40s 150ms/step - loss: 1.1921e-07 - accuracy: 0.1172 - val_loss: 1.1921e-07 - val_accuracy: 0.2188\n","Epoch 75/100\n","267/267 [==============================] - 38s 143ms/step - loss: 1.1921e-07 - accuracy: 0.1192 - val_loss: 1.1921e-07 - val_accuracy: 0.1250\n","Epoch 76/100\n","267/267 [==============================] - 38s 142ms/step - loss: 1.1921e-07 - accuracy: 0.1160 - val_loss: 1.1921e-07 - val_accuracy: 0.1250\n","Epoch 77/100\n","267/267 [==============================] - 38s 144ms/step - loss: 1.1921e-07 - accuracy: 0.1173 - val_loss: 1.1921e-07 - val_accuracy: 0.1719\n","Epoch 78/100\n","267/267 [==============================] - 38s 141ms/step - loss: 1.1921e-07 - accuracy: 0.1187 - val_loss: 1.1921e-07 - val_accuracy: 0.1406\n","Epoch 79/100\n","267/267 [==============================] - 38s 143ms/step - loss: 1.1921e-07 - accuracy: 0.1171 - val_loss: 1.1921e-07 - val_accuracy: 0.1094\n","Epoch 80/100\n","267/267 [==============================] - 38s 143ms/step - loss: 1.1921e-07 - accuracy: 0.1201 - val_loss: 1.1921e-07 - val_accuracy: 0.1250\n","Epoch 81/100\n","267/267 [==============================] - 38s 142ms/step - loss: 1.1921e-07 - accuracy: 0.1156 - val_loss: 1.1921e-07 - val_accuracy: 0.0469\n","Epoch 82/100\n","267/267 [==============================] - 38s 144ms/step - loss: 1.1921e-07 - accuracy: 0.1186 - val_loss: 1.1921e-07 - val_accuracy: 0.1094\n","Epoch 83/100\n","267/267 [==============================] - 38s 143ms/step - loss: 1.1921e-07 - accuracy: 0.1166 - val_loss: 1.1921e-07 - val_accuracy: 0.0784\n","Epoch 84/100\n","267/267 [==============================] - 38s 141ms/step - loss: 1.1921e-07 - accuracy: 0.1186 - val_loss: 1.1921e-07 - val_accuracy: 0.0625\n","Epoch 85/100\n","267/267 [==============================] - 39s 145ms/step - loss: 1.1921e-07 - accuracy: 0.1209 - val_loss: 1.1921e-07 - val_accuracy: 0.1406\n","Epoch 86/100\n","267/267 [==============================] - 38s 142ms/step - loss: 1.1921e-07 - accuracy: 0.1123 - val_loss: 1.1921e-07 - val_accuracy: 0.0938\n","Epoch 87/100\n","267/267 [==============================] - 38s 143ms/step - loss: 1.1921e-07 - accuracy: 0.1185 - val_loss: 1.1921e-07 - val_accuracy: 0.1406\n","Epoch 88/100\n","267/267 [==============================] - 38s 144ms/step - loss: 1.1921e-07 - accuracy: 0.1182 - val_loss: 1.1921e-07 - val_accuracy: 0.0469\n","Epoch 89/100\n","267/267 [==============================] - 38s 143ms/step - loss: 1.1921e-07 - accuracy: 0.1190 - val_loss: 1.1921e-07 - val_accuracy: 0.1094\n","Epoch 90/100\n","267/267 [==============================] - 39s 144ms/step - loss: 1.1921e-07 - accuracy: 0.1160 - val_loss: 1.1921e-07 - val_accuracy: 0.1875\n","Epoch 91/100\n","267/267 [==============================] - 39s 145ms/step - loss: 1.1921e-07 - accuracy: 0.1151 - val_loss: 1.1921e-07 - val_accuracy: 0.0781\n","Epoch 92/100\n","267/267 [==============================] - 38s 144ms/step - loss: 1.1921e-07 - accuracy: 0.1190 - val_loss: 1.1921e-07 - val_accuracy: 0.1094\n","Epoch 93/100\n","267/267 [==============================] - 39s 145ms/step - loss: 1.1921e-07 - accuracy: 0.1172 - val_loss: 1.1921e-07 - val_accuracy: 0.0938\n","Epoch 94/100\n","267/267 [==============================] - 39s 145ms/step - loss: 1.1921e-07 - accuracy: 0.1187 - val_loss: 1.1921e-07 - val_accuracy: 0.1250\n","Epoch 95/100\n","267/267 [==============================] - 39s 148ms/step - loss: 1.1921e-07 - accuracy: 0.1157 - val_loss: 1.1921e-07 - val_accuracy: 0.0938\n","Epoch 96/100\n","267/267 [==============================] - 39s 145ms/step - loss: 1.1921e-07 - accuracy: 0.1185 - val_loss: 1.1921e-07 - val_accuracy: 0.1094\n","Epoch 97/100\n","267/267 [==============================] - 38s 142ms/step - loss: 1.1921e-07 - accuracy: 0.1180 - val_loss: 1.1921e-07 - val_accuracy: 0.1719\n","Epoch 98/100\n","267/267 [==============================] - 38s 142ms/step - loss: 1.1921e-07 - accuracy: 0.1187 - val_loss: 1.1921e-07 - val_accuracy: 0.1250\n","Epoch 99/100\n","267/267 [==============================] - 40s 151ms/step - loss: 1.1921e-07 - accuracy: 0.1169 - val_loss: 1.1921e-07 - val_accuracy: 0.0781\n","Epoch 100/100\n","267/267 [==============================] - 38s 142ms/step - loss: 1.1921e-07 - accuracy: 0.1161 - val_loss: 1.1921e-07 - val_accuracy: 0.1562\n"]}],"source":["# 8534 images, 32 batch size \n","history = transfer_model.fit_generator(training_generator,\n","                   steps_per_epoch =267, #Number of iterations = number of training images (49,225) / batch size (255)  \n","                   epochs = 100, \n","                   validation_data = validation_generator,\n","                   validation_steps = 2, #same for validation data 300 validation images\n","                   shuffle = True) \n","transfer_model.save('/content/gdrive/MyDrive/final/us8k_TeslaP100_vgg16_32batchsize_100epochs_Param.h5')"]},{"cell_type":"markdown","metadata":{"id":"3Uy4h22anX9o"},"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":335},"executionInfo":{"elapsed":2083,"status":"error","timestamp":1651501057413,"user":{"displayName":"Gracie G. Becongco","userId":"00295426205393146083"},"user_tz":-120},"id":"A7ifXbhEvwj6","outputId":"7828d964-15c8-4167-f002-493ffc63dae5"},"outputs":[{"ename":"AttributeError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-97268b2affa2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive/MyDrive/final/AED_TeslaP100_vgg16_full_193_Param.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tensorflow-1.15.2/python3.7/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_filepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mload_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mload_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-1.15.2/python3.7/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mH5Dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_supported_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mH5Dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mh5dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 584\u001b[0;31m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deserialize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh5dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    585\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'write'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mload_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh5file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-1.15.2/python3.7/keras/engine/saving.py\u001b[0m in \u001b[0;36m_deserialize_model\u001b[0;34m(h5dict, custom_objects, compile)\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmodel_config\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No model found in config.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m     \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_from_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0mmodel_weights_group\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'decode'"]}],"source":["from keras.models import load_model\n","model = load_model('/content/gdrive/MyDrive/final/AED_TeslaP100_vgg16_full_1082_Param.h5')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":607},"executionInfo":{"elapsed":11277,"status":"ok","timestamp":1652983158900,"user":{"displayName":"Gracie G. Becongco","userId":"00295426205393146083"},"user_tz":-120},"id":"14l9iqlH43ea","outputId":"696df945-a913-4a22-e390-ac1dfcb51fc5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting h5py==2.10.0\n","  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n","\u001b[K     |████████████████████████████████| 2.9 MB 5.1 MB/s \n","\u001b[?25hCollecting numpy>=1.7\n","  Downloading numpy-1.21.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n","\u001b[K     |████████████████████████████████| 15.7 MB 92.4 MB/s \n","\u001b[?25hCollecting six\n","  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n","Installing collected packages: six, numpy, h5py\n","  Attempting uninstall: six\n","    Found existing installation: six 1.15.0\n","    Uninstalling six-1.15.0:\n","      Successfully uninstalled six-1.15.0\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.21.6\n","    Uninstalling numpy-1.21.6:\n","      Successfully uninstalled numpy-1.21.6\n","  Attempting uninstall: h5py\n","    Found existing installation: h5py 3.1.0\n","    Uninstalling h5py-3.1.0:\n","      Successfully uninstalled h5py-3.1.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow 2.8.0+zzzcolab20220506162203 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\n","google-colab 1.0.0 requires six~=1.15.0, but you have six 1.16.0 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n","albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Successfully installed h5py-2.10.0 numpy-1.21.6 six-1.16.0\n"]},{"data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy","six"]}}},"metadata":{},"output_type":"display_data"}],"source":["!pip install 'h5py==2.10.0' --force-reinstall"]},{"cell_type":"markdown","metadata":{"id":"31ovqz73ndSS"},"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UgI1iKJS5BqL"},"outputs":[],"source":[""]},{"cell_type":"markdown","metadata":{"id":"rXKjbMfLneyQ"},"source":["Model Testing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WkH6M5Mev4kJ"},"outputs":[],"source":["from keras.preprocessing.image import array_to_img, img_to_array, load_img\n","from keras.applications.vgg16 import preprocess_input\n","import numpy as np\n","import os\n","img_size = 224\n","dir_loc ='/content/gdrive/MyDrive/final/dataset3/test'\n","clssN = os.listdir(dir_loc)\n","\n","#clssN = ['Heidelberglaan15','Padualaan101','Padualaan97']\n","count = 0\n","countT = 0\n","for bl in clssN:\n","  src = './dataset/test/' + bl \n","  imgs = os.listdir(src)\n","  count = 0\n","  countT = len(imgs) #total number of images per class\n","  for img in imgs: \n","    im = load_img(src + \"/\" + img)\n","    w,h = im.size\n","    im = im.resize((int(w*0.2),int(h*0.2)))\n","    im = im.resize((img_size,img_size))\n","    x = img_to_array(im)  \n","    x = np.expand_dims(x, axis=0)\n","    x = preprocess_input(x)\n","    x/=255.\n","    probs = transfer_model.predict(x, verbose=0)\n","    maxDet = max(probs[0])\n","    maxIdx = list(probs[0]).index(maxDet) #predicted class with maximum probability\n","    if (clssN[maxIdx]==bl): \n","      count = count + 1  #count for true predictions (true positives)\n","    else:\n","      print(f'Wrong prediction of {bl}  {img}. Predicted as {clssN[maxIdx]}') \n","  print(f'test accuracy for {bl} is {str(count/countT)}')"]},{"cell_type":"markdown","metadata":{"id":"v3oraEgunsE3"},"source":["Using the below code, you will see the output of what building class the model has predicted for this specific image."]},{"cell_type":"markdown","metadata":{"id":"P4HbbDUH8gRH"},"source":["Plotting loss and accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X_o9ddF5ZPhg"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":517},"executionInfo":{"elapsed":784,"status":"error","timestamp":1651501202750,"user":{"displayName":"Gracie G. Becongco","userId":"00295426205393146083"},"user_tz":-120},"id":"cj9TNNmkj0Dh","outputId":"ab9ae3f0-7e25-4801-ea82-465fc06b7a2f"},"outputs":[{"ename":"KeyError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-7ab4190add0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mepoch_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m31\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0max1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Train Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0max1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Validation Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0max1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m31\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'acc'"]},{"data":{"image/png":"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\n","text/plain":["<Figure size 864x288 with 2 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["#import matplotlib as plt\n","import matplotlib.pyplot as plt\n","f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n","t = f.suptitle('Pre-trained CNN (Transfer Learning) Performance', fontsize=12)\n","f.subplots_adjust(top=0.85, wspace=0.3)\n","\n","epoch_list = list(range(1,31))\n","ax1.plot(epoch_list, history.history['acc'], label='Train Accuracy')\n","ax1.plot(epoch_list, history.history['val_acc'], label='Validation Accuracy')\n","ax1.set_xticks(np.arange(0, 31, 5))\n","ax1.set_ylabel('Accuracy Value')\n","ax1.set_xlabel('Epoch')\n","ax1.set_title('Accuracy')\n","l1 = ax1.legend(loc=\"best\")\n","\n","ax2.plot(epoch_list, history.history['loss'], label='Train Loss')\n","ax2.plot(epoch_list, history.history['val_loss'], label='Validation Loss')\n","ax2.set_xticks(np.arange(0, 31, 5))\n","ax2.set_ylabel('Loss Value')\n","ax2.set_xlabel('Epoch')\n","ax2.set_title('Loss')\n","l2 = ax2.legend(loc=\"best\")"]},{"cell_type":"code","source":[""],"metadata":{"id":"v1qqqqRNMauB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"fquJXLMnMaxH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"g7QGIg1FMa11"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"background_execution":"on","collapsed_sections":[],"machine_shape":"hm","name":"VGG16_fulldate_model_build_v1.ipynb","provenance":[{"file_id":"1v3m157wSmzu5ZtUhX3Xwq-nwEOUeLB2a","timestamp":1651264187924},{"file_id":"1-4FdKU4owdZ_lQweMIwVLT7bUDEGyVeJ","timestamp":1651074058284}],"authorship_tag":"ABX9TyMzsboZJMpek1aFW5V9cvWD"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}